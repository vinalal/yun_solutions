{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "cEL4ba8bgy1G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v-IEN6-fY7vK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77df3ece-81ce-4386-dbd9-123d65db8249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3528 entries, 0 to 3527\n",
            "Data columns (total 17 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   _id                3528 non-null   object\n",
            " 1   daysToExpiry       3528 non-null   object\n",
            " 2   expiry             3528 non-null   object\n",
            " 3   index              3528 non-null   object\n",
            " 4   close              3528 non-null   object\n",
            " 5   date               3528 non-null   object\n",
            " 6   high               3528 non-null   object\n",
            " 7   index_close        3528 non-null   object\n",
            " 8   index_high         3528 non-null   object\n",
            " 9   index_low          3528 non-null   object\n",
            " 10  index_open         3528 non-null   object\n",
            " 11  intradayMovement   3528 non-null   object\n",
            " 12  intradayTotal      3528 non-null   object\n",
            " 13  low                3528 non-null   object\n",
            " 14  open               3528 non-null   object\n",
            " 15  overnightExpected  3528 non-null   object\n",
            " 16  overnightGap       3528 non-null   object\n",
            "dtypes: object(17)\n",
            "memory usage: 468.7+ KB\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "columns = ['_id', 'daysToExpiry', 'expiry', 'index', 'close', 'date', 'high',\n",
        "       'index_close', 'index_high', 'index_low', 'index_open',\n",
        "       'intradayMovement', 'intradayTotal', 'low', 'open', 'overnightExpected',\n",
        "       'overnightGap']\n",
        "\n",
        "\n",
        "dte = [0,1,2,3,4]\n",
        "\n",
        "def get_for_index(ind):\n",
        "  url = f\"https://live.markethound.in/api/history/expiries?index={ind}\"\n",
        "  response = requests.get(url)\n",
        "  expiries = response.json()[\"result\"]\n",
        "  return expiries\n",
        "\n",
        "def get_for_index_dte_list(ind,expiry_list):\n",
        "  combined_df_for_index = pd.DataFrame(columns=columns)\n",
        "  for expiry in expiry_list:\n",
        "    for i in range(6):\n",
        "      url = f\"https://live.markethound.in/api/history/decay?name={ind}&expiry={expiry}&dte={str(i)}\"\n",
        "      response = requests.get(url)\n",
        "      if response.status_code != 200:\n",
        "        print(\"error\")\n",
        "      data = response.json()\n",
        "      result = data.get(\"result\", [])\n",
        "      df = pd.DataFrame(result)\n",
        "      combined_df_for_index = pd.concat([combined_df_for_index, df], axis=0, ignore_index=True)\n",
        "  return combined_df_for_index\n",
        "\n",
        "def get_data():\n",
        "  combined_df = pd.DataFrame(columns=columns)\n",
        "  indices = [\"NIFTY\", \"SENSEX\", \"FINNIFTY\",\"BANKEX\"]\n",
        "  for ind in indices:\n",
        "    expiry_list = get_for_index(ind)\n",
        "    df = get_for_index_dte_list(ind,expiry_list)\n",
        "    combined_df = pd.concat([combined_df, df], axis=0, ignore_index=True)\n",
        "\n",
        "  return combined_df\n",
        "\n",
        "\n",
        "df_full = get_data()\n",
        "df_full.info()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_convert = [ 'daysToExpiry', 'close', 'date', 'high',\n",
        "       'index_close', 'index_high', 'index_low', 'index_open',\n",
        "       'intradayMovement', 'intradayTotal', 'low', 'open', 'overnightExpected',\n",
        "       'overnightGap']  # List of columns to convert\n",
        "\n",
        "# Convert selected columns to numeric\n",
        "df_full[columns_to_convert] = df_full[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n"
      ],
      "metadata": {
        "id": "gLWnMzBBSluX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_full.info()\n",
        "df_full_sorted = df_full.sort_values(by=['expiry', 'daysToExpiry'], ascending=[True, False])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcmUhsR8eteA",
        "outputId": "acf8beaf-d581-4851-8007-01ab1f498616"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3528 entries, 0 to 3527\n",
            "Data columns (total 17 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   _id                3528 non-null   object \n",
            " 1   daysToExpiry       3528 non-null   int64  \n",
            " 2   expiry             3528 non-null   object \n",
            " 3   index              3528 non-null   object \n",
            " 4   close              3528 non-null   float64\n",
            " 5   date               0 non-null      float64\n",
            " 6   high               3528 non-null   float64\n",
            " 7   index_close        3528 non-null   float64\n",
            " 8   index_high         3528 non-null   float64\n",
            " 9   index_low          3528 non-null   float64\n",
            " 10  index_open         3528 non-null   float64\n",
            " 11  intradayMovement   3528 non-null   float64\n",
            " 12  intradayTotal      3528 non-null   float64\n",
            " 13  low                3528 non-null   float64\n",
            " 14  open               3528 non-null   float64\n",
            " 15  overnightExpected  3528 non-null   float64\n",
            " 16  overnightGap       3528 non-null   float64\n",
            "dtypes: float64(13), int64(1), object(3)\n",
            "memory usage: 468.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_features_and_targets(df):\n",
        "    # Create features\n",
        "    features = df[['expiry','daysToExpiry', 'intradayMovement', 'intradayTotal', 'overnightExpected', 'overnightGap',\n",
        "                   'index_close', 'index_high', 'index_low', 'index_open']]\n",
        "\n",
        "    features = features[df['daysToExpiry'].isin([1, 2, 3, 4, 5])]\n",
        "    next_day_expiry_values = features['daysToExpiry'] - 1\n",
        "\n",
        "    # Filter rows that satisfy the condition\n",
        "    filtered_rows = df[(df['expiry'].isin(features['expiry'])) & (df['daysToExpiry'].isin(next_day_expiry_values))]\n",
        "\n",
        "    # Create an empty DataFrame with the same structure as features\n",
        "    targets = pd.DataFrame(columns=['high', 'low', 'open', 'close'])\n",
        "\n",
        "    # Fill in the rows that match the condition\n",
        "    if not filtered_rows.empty:\n",
        "        targets = targets.append(filtered_rows[['high', 'low', 'open', 'close']])\n",
        "        # Fill the missing rows with zeros\n",
        "        targets = targets.reindex(index=features.index, fill_value=0)\n",
        "    else:\n",
        "        # If no rows satisfy the condition, fill targets with zeros\n",
        "        targets = pd.DataFrame(np.zeros((features.shape[0], 4)), columns=['high', 'low', 'open', 'close'])\n",
        "\n",
        "    # Drop 'expiry' column from features if needed\n",
        "    features = features.drop('expiry', axis=1)\n",
        "\n",
        "    return features, targets\n",
        "\n",
        "# Function to prepare data for LSTM model\n",
        "def prepare_data(df):\n",
        "    # Scale the features\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_features = scaler.fit_transform(df)\n",
        "\n",
        "    # Reshape data into LSTM input shape [samples, time steps, features]\n",
        "    X = np.reshape(scaled_features, (scaled_features.shape[0], 1, scaled_features.shape[1]))\n",
        "    return X\n",
        "\n",
        "# Defining an LSTM model\n",
        "def build_lstm_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(units=50, return_sequences=True, input_shape=input_shape),\n",
        "        Dropout(0.2),\n",
        "        LSTM(units=50, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "        Dense(units=4)  # Output layer for 4 target variables (open, high, low, close)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')  # Use Mean Squared Error loss\n",
        "    return model\n",
        "\n",
        "\n",
        "# Iterate over indices and train models\n",
        "indices = [\"NIFTY\", \"SENSEX\", \"FINNIFTY\", \"BANKEX\"]\n",
        "# Iterate over indices and train models\n",
        "lstm_models = {}\n",
        "\n",
        "for index in indices:\n",
        "    index_data = df_full[df_full[\"index\"] == index]\n",
        "    train_data, test_data = train_test_split(index_data, test_size=0.2, random_state=42)\n",
        "    train_features, train_targets = create_features_and_targets(train_data)\n",
        "    test_features, test_targets = create_features_and_targets(test_data)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = MinMaxScaler()\n",
        "    train_features_scaled = scaler.fit_transform(train_features)\n",
        "    test_features_scaled = scaler.transform(test_features)\n",
        "\n",
        "    # Convert data to float32 and reshape for LSTM\n",
        "    X_train = np.asarray(train_features_scaled).astype(np.float32)\n",
        "    y_train = np.asarray(train_targets).astype(np.float32)\n",
        "    X_test = np.asarray(test_features_scaled).astype(np.float32)\n",
        "    y_test = np.asarray(test_targets).astype(np.float32)\n",
        "\n",
        "    # Reshape data for LSTM (assuming input_shape is (timesteps, features))\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "    # Build and train the LSTM model\n",
        "    lstm_model = build_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
        "    lstm_model.fit(X_train, y_train, epochs=250, batch_size=32, verbose=2, validation_split=0.1)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mse = lstm_model.evaluate(X_test, y_test)\n",
        "    print(f\"Index: {index}, Test MSE: {mse}\")\n",
        "\n",
        "    lstm_models[index] = lstm_model\n",
        "\n",
        "\n",
        "# Make predictions for the next day's stock prices for each index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSnjOr8bg9sb",
        "outputId": "5def4036-a7ed-447c-f717-9938c2775e5f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-6d1f8824e18c>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  targets = targets.append(filtered_rows[['high', 'low', 'open', 'close']])\n",
            "<ipython-input-27-6d1f8824e18c>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  targets = targets.append(filtered_rows[['high', 'low', 'open', 'close']])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "19/19 - 5s - loss: 30488.2812 - val_loss: 30756.0859 - 5s/epoch - 244ms/step\n",
            "Epoch 2/250\n",
            "19/19 - 0s - loss: 30441.8906 - val_loss: 30681.8691 - 94ms/epoch - 5ms/step\n",
            "Epoch 3/250\n",
            "19/19 - 0s - loss: 30313.5625 - val_loss: 30460.5195 - 89ms/epoch - 5ms/step\n",
            "Epoch 4/250\n",
            "19/19 - 0s - loss: 29968.0957 - val_loss: 29968.2012 - 93ms/epoch - 5ms/step\n",
            "Epoch 5/250\n",
            "19/19 - 0s - loss: 29367.3574 - val_loss: 29291.2051 - 95ms/epoch - 5ms/step\n",
            "Epoch 6/250\n",
            "19/19 - 0s - loss: 28671.0449 - val_loss: 28651.8438 - 108ms/epoch - 6ms/step\n",
            "Epoch 7/250\n",
            "19/19 - 0s - loss: 28119.6348 - val_loss: 28133.1328 - 99ms/epoch - 5ms/step\n",
            "Epoch 8/250\n",
            "19/19 - 0s - loss: 27620.4883 - val_loss: 27719.1895 - 111ms/epoch - 6ms/step\n",
            "Epoch 9/250\n",
            "19/19 - 0s - loss: 27254.4648 - val_loss: 27361.8398 - 107ms/epoch - 6ms/step\n",
            "Epoch 10/250\n",
            "19/19 - 0s - loss: 26864.8535 - val_loss: 27050.5488 - 114ms/epoch - 6ms/step\n",
            "Epoch 11/250\n",
            "19/19 - 0s - loss: 26577.5625 - val_loss: 26762.1543 - 98ms/epoch - 5ms/step\n",
            "Epoch 12/250\n",
            "19/19 - 0s - loss: 26313.1758 - val_loss: 26493.3242 - 110ms/epoch - 6ms/step\n",
            "Epoch 13/250\n",
            "19/19 - 0s - loss: 26046.6875 - val_loss: 26240.9648 - 112ms/epoch - 6ms/step\n",
            "Epoch 14/250\n",
            "19/19 - 0s - loss: 25795.4727 - val_loss: 25999.7227 - 91ms/epoch - 5ms/step\n",
            "Epoch 15/250\n",
            "19/19 - 0s - loss: 25551.2031 - val_loss: 25770.7227 - 95ms/epoch - 5ms/step\n",
            "Epoch 16/250\n",
            "19/19 - 0s - loss: 25355.5391 - val_loss: 25548.9160 - 114ms/epoch - 6ms/step\n",
            "Epoch 17/250\n",
            "19/19 - 0s - loss: 25097.7949 - val_loss: 25331.2383 - 90ms/epoch - 5ms/step\n",
            "Epoch 18/250\n",
            "19/19 - 0s - loss: 24883.1621 - val_loss: 25113.7910 - 93ms/epoch - 5ms/step\n",
            "Epoch 19/250\n",
            "19/19 - 0s - loss: 24679.9746 - val_loss: 24908.1973 - 108ms/epoch - 6ms/step\n",
            "Epoch 20/250\n",
            "19/19 - 0s - loss: 24477.5332 - val_loss: 24704.1719 - 107ms/epoch - 6ms/step\n",
            "Epoch 21/250\n",
            "19/19 - 0s - loss: 24270.3984 - val_loss: 24506.4219 - 111ms/epoch - 6ms/step\n",
            "Epoch 22/250\n",
            "19/19 - 0s - loss: 24058.2129 - val_loss: 24311.8496 - 94ms/epoch - 5ms/step\n",
            "Epoch 23/250\n",
            "19/19 - 0s - loss: 23849.6426 - val_loss: 24115.7676 - 104ms/epoch - 5ms/step\n",
            "Epoch 24/250\n",
            "19/19 - 0s - loss: 23707.8379 - val_loss: 23929.6562 - 111ms/epoch - 6ms/step\n",
            "Epoch 25/250\n",
            "19/19 - 0s - loss: 23509.8633 - val_loss: 23748.3184 - 101ms/epoch - 5ms/step\n",
            "Epoch 26/250\n",
            "19/19 - 0s - loss: 23297.9805 - val_loss: 23564.5801 - 106ms/epoch - 6ms/step\n",
            "Epoch 27/250\n",
            "19/19 - 0s - loss: 23149.8184 - val_loss: 23388.1836 - 114ms/epoch - 6ms/step\n",
            "Epoch 28/250\n",
            "19/19 - 0s - loss: 22913.8379 - val_loss: 23210.9629 - 106ms/epoch - 6ms/step\n",
            "Epoch 29/250\n",
            "19/19 - 0s - loss: 22776.6543 - val_loss: 23035.0469 - 118ms/epoch - 6ms/step\n",
            "Epoch 30/250\n",
            "19/19 - 0s - loss: 22617.1465 - val_loss: 22862.5957 - 92ms/epoch - 5ms/step\n",
            "Epoch 31/250\n",
            "19/19 - 0s - loss: 22427.6875 - val_loss: 22692.0566 - 95ms/epoch - 5ms/step\n",
            "Epoch 32/250\n",
            "19/19 - 0s - loss: 22230.6738 - val_loss: 22525.5312 - 108ms/epoch - 6ms/step\n",
            "Epoch 33/250\n",
            "19/19 - 0s - loss: 22074.5996 - val_loss: 22358.3047 - 106ms/epoch - 6ms/step\n",
            "Epoch 34/250\n",
            "19/19 - 0s - loss: 21861.6152 - val_loss: 22191.7930 - 116ms/epoch - 6ms/step\n",
            "Epoch 35/250\n",
            "19/19 - 0s - loss: 21755.0195 - val_loss: 22028.2344 - 95ms/epoch - 5ms/step\n",
            "Epoch 36/250\n",
            "19/19 - 0s - loss: 21622.6816 - val_loss: 21870.3906 - 94ms/epoch - 5ms/step\n",
            "Epoch 37/250\n",
            "19/19 - 0s - loss: 21465.1348 - val_loss: 21714.2188 - 93ms/epoch - 5ms/step\n",
            "Epoch 38/250\n",
            "19/19 - 0s - loss: 21255.8223 - val_loss: 21557.8438 - 100ms/epoch - 5ms/step\n",
            "Epoch 39/250\n",
            "19/19 - 0s - loss: 21112.5469 - val_loss: 21402.7070 - 94ms/epoch - 5ms/step\n",
            "Epoch 40/250\n",
            "19/19 - 0s - loss: 20933.6777 - val_loss: 21250.1797 - 108ms/epoch - 6ms/step\n",
            "Epoch 41/250\n",
            "19/19 - 0s - loss: 20770.3223 - val_loss: 21097.0938 - 105ms/epoch - 6ms/step\n",
            "Epoch 42/250\n",
            "19/19 - 0s - loss: 20698.5254 - val_loss: 20949.7188 - 110ms/epoch - 6ms/step\n",
            "Epoch 43/250\n",
            "19/19 - 0s - loss: 20422.7031 - val_loss: 20799.9414 - 110ms/epoch - 6ms/step\n",
            "Epoch 44/250\n",
            "19/19 - 0s - loss: 20332.5391 - val_loss: 20654.4492 - 111ms/epoch - 6ms/step\n",
            "Epoch 45/250\n",
            "19/19 - 0s - loss: 20174.0195 - val_loss: 20507.7168 - 91ms/epoch - 5ms/step\n",
            "Epoch 46/250\n",
            "19/19 - 0s - loss: 20084.7734 - val_loss: 20363.4941 - 92ms/epoch - 5ms/step\n",
            "Epoch 47/250\n",
            "19/19 - 0s - loss: 19824.5156 - val_loss: 20223.6895 - 109ms/epoch - 6ms/step\n",
            "Epoch 48/250\n",
            "19/19 - 0s - loss: 19752.8047 - val_loss: 20083.6445 - 116ms/epoch - 6ms/step\n",
            "Epoch 49/250\n",
            "19/19 - 0s - loss: 19632.7656 - val_loss: 19944.3418 - 95ms/epoch - 5ms/step\n",
            "Epoch 50/250\n",
            "19/19 - 0s - loss: 19499.0703 - val_loss: 19808.1250 - 109ms/epoch - 6ms/step\n",
            "Epoch 51/250\n",
            "19/19 - 0s - loss: 19374.1230 - val_loss: 19672.9023 - 138ms/epoch - 7ms/step\n",
            "Epoch 52/250\n",
            "19/19 - 0s - loss: 19268.6191 - val_loss: 19538.1895 - 146ms/epoch - 8ms/step\n",
            "Epoch 53/250\n",
            "19/19 - 0s - loss: 19071.8301 - val_loss: 19403.7910 - 148ms/epoch - 8ms/step\n",
            "Epoch 54/250\n",
            "19/19 - 0s - loss: 18940.1074 - val_loss: 19273.8887 - 137ms/epoch - 7ms/step\n",
            "Epoch 55/250\n",
            "19/19 - 0s - loss: 18853.1602 - val_loss: 19142.8047 - 136ms/epoch - 7ms/step\n",
            "Epoch 56/250\n",
            "19/19 - 0s - loss: 18664.3516 - val_loss: 19017.9590 - 149ms/epoch - 8ms/step\n",
            "Epoch 57/250\n",
            "19/19 - 0s - loss: 18555.6230 - val_loss: 18890.8047 - 131ms/epoch - 7ms/step\n",
            "Epoch 58/250\n",
            "19/19 - 0s - loss: 18413.0176 - val_loss: 18763.7695 - 142ms/epoch - 7ms/step\n",
            "Epoch 59/250\n",
            "19/19 - 0s - loss: 18370.0449 - val_loss: 18639.1367 - 149ms/epoch - 8ms/step\n",
            "Epoch 60/250\n",
            "19/19 - 0s - loss: 18114.3574 - val_loss: 18517.0762 - 154ms/epoch - 8ms/step\n",
            "Epoch 61/250\n",
            "19/19 - 0s - loss: 18061.7402 - val_loss: 18395.1934 - 144ms/epoch - 8ms/step\n",
            "Epoch 62/250\n",
            "19/19 - 0s - loss: 17915.8262 - val_loss: 18273.9160 - 173ms/epoch - 9ms/step\n",
            "Epoch 63/250\n",
            "19/19 - 0s - loss: 17776.3398 - val_loss: 18149.9180 - 159ms/epoch - 8ms/step\n",
            "Epoch 64/250\n",
            "19/19 - 0s - loss: 17701.5996 - val_loss: 18032.1133 - 140ms/epoch - 7ms/step\n",
            "Epoch 65/250\n",
            "19/19 - 0s - loss: 17514.9551 - val_loss: 17916.6406 - 134ms/epoch - 7ms/step\n",
            "Epoch 66/250\n",
            "19/19 - 0s - loss: 17387.0469 - val_loss: 17800.5430 - 99ms/epoch - 5ms/step\n",
            "Epoch 67/250\n",
            "19/19 - 0s - loss: 17280.5742 - val_loss: 17684.5039 - 106ms/epoch - 6ms/step\n",
            "Epoch 68/250\n",
            "19/19 - 0s - loss: 17194.2832 - val_loss: 17571.1133 - 92ms/epoch - 5ms/step\n",
            "Epoch 69/250\n",
            "19/19 - 0s - loss: 17096.0625 - val_loss: 17457.7578 - 109ms/epoch - 6ms/step\n",
            "Epoch 70/250\n",
            "19/19 - 0s - loss: 16982.2266 - val_loss: 17344.7070 - 107ms/epoch - 6ms/step\n",
            "Epoch 71/250\n",
            "19/19 - 0s - loss: 16798.6582 - val_loss: 17235.7734 - 109ms/epoch - 6ms/step\n",
            "Epoch 72/250\n",
            "19/19 - 0s - loss: 16732.5820 - val_loss: 17127.0645 - 111ms/epoch - 6ms/step\n",
            "Epoch 73/250\n",
            "19/19 - 0s - loss: 16644.8613 - val_loss: 17018.2520 - 98ms/epoch - 5ms/step\n",
            "Epoch 74/250\n",
            "19/19 - 0s - loss: 16474.3984 - val_loss: 16912.2266 - 105ms/epoch - 6ms/step\n",
            "Epoch 75/250\n",
            "19/19 - 0s - loss: 16407.4766 - val_loss: 16807.7656 - 91ms/epoch - 5ms/step\n",
            "Epoch 76/250\n",
            "19/19 - 0s - loss: 16394.2441 - val_loss: 16702.8398 - 110ms/epoch - 6ms/step\n",
            "Epoch 77/250\n",
            "19/19 - 0s - loss: 16208.3330 - val_loss: 16597.7891 - 106ms/epoch - 6ms/step\n",
            "Epoch 78/250\n",
            "19/19 - 0s - loss: 16147.5586 - val_loss: 16498.5742 - 94ms/epoch - 5ms/step\n",
            "Epoch 79/250\n",
            "19/19 - 0s - loss: 15969.7998 - val_loss: 16396.0664 - 112ms/epoch - 6ms/step\n",
            "Epoch 80/250\n",
            "19/19 - 0s - loss: 15933.0488 - val_loss: 16295.9600 - 116ms/epoch - 6ms/step\n",
            "Epoch 81/250\n",
            "19/19 - 0s - loss: 15874.4121 - val_loss: 16197.4414 - 94ms/epoch - 5ms/step\n",
            "Epoch 82/250\n",
            "19/19 - 0s - loss: 15730.5059 - val_loss: 16100.7861 - 97ms/epoch - 5ms/step\n",
            "Epoch 83/250\n",
            "19/19 - 0s - loss: 15623.5176 - val_loss: 16002.3242 - 106ms/epoch - 6ms/step\n",
            "Epoch 84/250\n",
            "19/19 - 0s - loss: 15558.3516 - val_loss: 15906.4336 - 89ms/epoch - 5ms/step\n",
            "Epoch 85/250\n",
            "19/19 - 0s - loss: 15389.8340 - val_loss: 15811.3643 - 92ms/epoch - 5ms/step\n",
            "Epoch 86/250\n",
            "19/19 - 0s - loss: 15356.7402 - val_loss: 15715.0166 - 105ms/epoch - 6ms/step\n",
            "Epoch 87/250\n",
            "19/19 - 0s - loss: 15215.1338 - val_loss: 15624.2627 - 107ms/epoch - 6ms/step\n",
            "Epoch 88/250\n",
            "19/19 - 0s - loss: 15128.3467 - val_loss: 15530.4209 - 113ms/epoch - 6ms/step\n",
            "Epoch 89/250\n",
            "19/19 - 0s - loss: 14981.8525 - val_loss: 15439.4082 - 97ms/epoch - 5ms/step\n",
            "Epoch 90/250\n",
            "19/19 - 0s - loss: 15035.6465 - val_loss: 15347.5801 - 112ms/epoch - 6ms/step\n",
            "Epoch 91/250\n",
            "19/19 - 0s - loss: 14882.5332 - val_loss: 15258.0059 - 111ms/epoch - 6ms/step\n",
            "Epoch 92/250\n",
            "19/19 - 0s - loss: 14788.5264 - val_loss: 15169.5283 - 95ms/epoch - 5ms/step\n",
            "Epoch 93/250\n",
            "19/19 - 0s - loss: 14629.8760 - val_loss: 15084.9531 - 107ms/epoch - 6ms/step\n",
            "Epoch 94/250\n",
            "19/19 - 0s - loss: 14628.1260 - val_loss: 14998.4961 - 99ms/epoch - 5ms/step\n",
            "Epoch 95/250\n",
            "19/19 - 0s - loss: 14515.6523 - val_loss: 14912.9365 - 108ms/epoch - 6ms/step\n",
            "Epoch 96/250\n",
            "19/19 - 0s - loss: 14402.9102 - val_loss: 14825.5811 - 97ms/epoch - 5ms/step\n",
            "Epoch 97/250\n",
            "19/19 - 0s - loss: 14361.9150 - val_loss: 14742.4014 - 102ms/epoch - 5ms/step\n",
            "Epoch 98/250\n",
            "19/19 - 0s - loss: 14182.4902 - val_loss: 14661.7256 - 95ms/epoch - 5ms/step\n",
            "Epoch 99/250\n",
            "19/19 - 0s - loss: 14130.5654 - val_loss: 14578.7695 - 94ms/epoch - 5ms/step\n",
            "Epoch 100/250\n",
            "19/19 - 0s - loss: 14015.2480 - val_loss: 14498.4336 - 102ms/epoch - 5ms/step\n",
            "Epoch 101/250\n",
            "19/19 - 0s - loss: 13909.2334 - val_loss: 14418.7539 - 109ms/epoch - 6ms/step\n",
            "Epoch 102/250\n",
            "19/19 - 0s - loss: 13804.0244 - val_loss: 14341.3516 - 106ms/epoch - 6ms/step\n",
            "Epoch 103/250\n",
            "19/19 - 0s - loss: 13823.9717 - val_loss: 14260.9014 - 109ms/epoch - 6ms/step\n",
            "Epoch 104/250\n",
            "19/19 - 0s - loss: 13781.3662 - val_loss: 14183.9648 - 113ms/epoch - 6ms/step\n",
            "Epoch 105/250\n",
            "19/19 - 0s - loss: 13653.6807 - val_loss: 14111.0762 - 108ms/epoch - 6ms/step\n",
            "Epoch 106/250\n",
            "19/19 - 0s - loss: 13709.7256 - val_loss: 14036.0215 - 107ms/epoch - 6ms/step\n",
            "Epoch 107/250\n",
            "19/19 - 0s - loss: 13564.7480 - val_loss: 13961.4766 - 95ms/epoch - 5ms/step\n",
            "Epoch 108/250\n",
            "19/19 - 0s - loss: 13497.0293 - val_loss: 13886.8252 - 107ms/epoch - 6ms/step\n",
            "Epoch 109/250\n",
            "19/19 - 0s - loss: 13379.7471 - val_loss: 13812.9043 - 110ms/epoch - 6ms/step\n",
            "Epoch 110/250\n",
            "19/19 - 0s - loss: 13360.2344 - val_loss: 13740.7002 - 94ms/epoch - 5ms/step\n",
            "Epoch 111/250\n",
            "19/19 - 0s - loss: 13204.0752 - val_loss: 13668.2539 - 93ms/epoch - 5ms/step\n",
            "Epoch 112/250\n",
            "19/19 - 0s - loss: 13179.5225 - val_loss: 13599.4072 - 93ms/epoch - 5ms/step\n",
            "Epoch 113/250\n",
            "19/19 - 0s - loss: 13220.4834 - val_loss: 13529.8057 - 106ms/epoch - 6ms/step\n",
            "Epoch 114/250\n",
            "19/19 - 0s - loss: 13075.7051 - val_loss: 13460.3242 - 109ms/epoch - 6ms/step\n",
            "Epoch 115/250\n",
            "19/19 - 0s - loss: 12937.3867 - val_loss: 13392.1582 - 94ms/epoch - 5ms/step\n",
            "Epoch 116/250\n",
            "19/19 - 0s - loss: 12826.9316 - val_loss: 13324.9590 - 98ms/epoch - 5ms/step\n",
            "Epoch 117/250\n",
            "19/19 - 0s - loss: 12793.1592 - val_loss: 13259.5605 - 112ms/epoch - 6ms/step\n",
            "Epoch 118/250\n",
            "19/19 - 0s - loss: 12744.9561 - val_loss: 13195.7197 - 91ms/epoch - 5ms/step\n",
            "Epoch 119/250\n",
            "19/19 - 0s - loss: 12682.6201 - val_loss: 13129.2334 - 112ms/epoch - 6ms/step\n",
            "Epoch 120/250\n",
            "19/19 - 0s - loss: 12611.5840 - val_loss: 13064.2773 - 95ms/epoch - 5ms/step\n",
            "Epoch 121/250\n",
            "19/19 - 0s - loss: 12573.5332 - val_loss: 13002.7178 - 105ms/epoch - 6ms/step\n",
            "Epoch 122/250\n",
            "19/19 - 0s - loss: 12483.5264 - val_loss: 12941.2793 - 107ms/epoch - 6ms/step\n",
            "Epoch 123/250\n",
            "19/19 - 0s - loss: 12490.3994 - val_loss: 12878.9023 - 110ms/epoch - 6ms/step\n",
            "Epoch 124/250\n",
            "19/19 - 0s - loss: 12397.9004 - val_loss: 12818.2383 - 94ms/epoch - 5ms/step\n",
            "Epoch 125/250\n",
            "19/19 - 0s - loss: 12173.6680 - val_loss: 12759.8877 - 107ms/epoch - 6ms/step\n",
            "Epoch 126/250\n",
            "19/19 - 0s - loss: 12238.2207 - val_loss: 12699.0986 - 103ms/epoch - 5ms/step\n",
            "Epoch 127/250\n",
            "19/19 - 0s - loss: 12257.3037 - val_loss: 12640.0146 - 96ms/epoch - 5ms/step\n",
            "Epoch 128/250\n",
            "19/19 - 0s - loss: 12096.1162 - val_loss: 12582.8701 - 93ms/epoch - 5ms/step\n",
            "Epoch 129/250\n",
            "19/19 - 0s - loss: 12045.1270 - val_loss: 12523.1553 - 100ms/epoch - 5ms/step\n",
            "Epoch 130/250\n",
            "19/19 - 0s - loss: 12050.3301 - val_loss: 12464.9834 - 109ms/epoch - 6ms/step\n",
            "Epoch 131/250\n",
            "19/19 - 0s - loss: 11911.3105 - val_loss: 12409.7109 - 90ms/epoch - 5ms/step\n",
            "Epoch 132/250\n",
            "19/19 - 0s - loss: 11898.6689 - val_loss: 12355.4346 - 107ms/epoch - 6ms/step\n",
            "Epoch 133/250\n",
            "19/19 - 0s - loss: 11812.6787 - val_loss: 12301.5869 - 99ms/epoch - 5ms/step\n",
            "Epoch 134/250\n",
            "19/19 - 0s - loss: 11803.8330 - val_loss: 12249.3271 - 119ms/epoch - 6ms/step\n",
            "Epoch 135/250\n",
            "19/19 - 0s - loss: 11700.2012 - val_loss: 12192.4717 - 114ms/epoch - 6ms/step\n",
            "Epoch 136/250\n",
            "19/19 - 0s - loss: 11703.0830 - val_loss: 12142.2900 - 96ms/epoch - 5ms/step\n",
            "Epoch 137/250\n",
            "19/19 - 0s - loss: 11638.8389 - val_loss: 12088.8965 - 107ms/epoch - 6ms/step\n",
            "Epoch 138/250\n",
            "19/19 - 0s - loss: 11606.1982 - val_loss: 12034.7979 - 95ms/epoch - 5ms/step\n",
            "Epoch 139/250\n",
            "19/19 - 0s - loss: 11563.8262 - val_loss: 11985.6875 - 114ms/epoch - 6ms/step\n",
            "Epoch 140/250\n",
            "19/19 - 0s - loss: 11466.9531 - val_loss: 11936.4590 - 98ms/epoch - 5ms/step\n",
            "Epoch 141/250\n",
            "19/19 - 0s - loss: 11505.4561 - val_loss: 11885.8936 - 99ms/epoch - 5ms/step\n",
            "Epoch 142/250\n",
            "19/19 - 0s - loss: 11311.7900 - val_loss: 11837.5117 - 102ms/epoch - 5ms/step\n",
            "Epoch 143/250\n",
            "19/19 - 0s - loss: 11294.2998 - val_loss: 11790.4619 - 95ms/epoch - 5ms/step\n",
            "Epoch 144/250\n",
            "19/19 - 0s - loss: 11110.8447 - val_loss: 11742.0938 - 93ms/epoch - 5ms/step\n",
            "Epoch 145/250\n",
            "19/19 - 0s - loss: 11187.8535 - val_loss: 11697.4492 - 97ms/epoch - 5ms/step\n",
            "Epoch 146/250\n",
            "19/19 - 0s - loss: 11265.1562 - val_loss: 11652.2012 - 94ms/epoch - 5ms/step\n",
            "Epoch 147/250\n",
            "19/19 - 0s - loss: 11112.0820 - val_loss: 11607.6641 - 92ms/epoch - 5ms/step\n",
            "Epoch 148/250\n",
            "19/19 - 0s - loss: 11080.7705 - val_loss: 11562.6445 - 93ms/epoch - 5ms/step\n",
            "Epoch 149/250\n",
            "19/19 - 0s - loss: 11120.2607 - val_loss: 11516.3926 - 101ms/epoch - 5ms/step\n",
            "Epoch 150/250\n",
            "19/19 - 0s - loss: 10947.2383 - val_loss: 11474.2783 - 98ms/epoch - 5ms/step\n",
            "Epoch 151/250\n",
            "19/19 - 0s - loss: 10943.5859 - val_loss: 11432.6797 - 95ms/epoch - 5ms/step\n",
            "Epoch 152/250\n",
            "19/19 - 0s - loss: 10922.3486 - val_loss: 11389.5186 - 105ms/epoch - 6ms/step\n",
            "Epoch 153/250\n",
            "19/19 - 0s - loss: 10860.0410 - val_loss: 11347.5801 - 94ms/epoch - 5ms/step\n",
            "Epoch 154/250\n",
            "19/19 - 0s - loss: 10804.7314 - val_loss: 11304.8066 - 97ms/epoch - 5ms/step\n",
            "Epoch 155/250\n",
            "19/19 - 0s - loss: 10779.9072 - val_loss: 11263.9473 - 92ms/epoch - 5ms/step\n",
            "Epoch 156/250\n",
            "19/19 - 0s - loss: 10673.9443 - val_loss: 11225.4385 - 103ms/epoch - 5ms/step\n",
            "Epoch 157/250\n",
            "19/19 - 0s - loss: 10710.9531 - val_loss: 11186.0283 - 94ms/epoch - 5ms/step\n",
            "Epoch 158/250\n",
            "19/19 - 0s - loss: 10569.6729 - val_loss: 11146.8594 - 108ms/epoch - 6ms/step\n",
            "Epoch 159/250\n",
            "19/19 - 0s - loss: 10533.0635 - val_loss: 11108.6553 - 125ms/epoch - 7ms/step\n",
            "Epoch 160/250\n",
            "19/19 - 0s - loss: 10533.2256 - val_loss: 11070.5859 - 139ms/epoch - 7ms/step\n",
            "Epoch 161/250\n",
            "19/19 - 0s - loss: 10482.2607 - val_loss: 11032.9180 - 150ms/epoch - 8ms/step\n",
            "Epoch 162/250\n",
            "19/19 - 0s - loss: 10474.3691 - val_loss: 10997.8359 - 151ms/epoch - 8ms/step\n",
            "Epoch 163/250\n",
            "19/19 - 0s - loss: 10406.4941 - val_loss: 10961.1553 - 129ms/epoch - 7ms/step\n",
            "Epoch 164/250\n",
            "19/19 - 0s - loss: 10452.8281 - val_loss: 10925.6514 - 135ms/epoch - 7ms/step\n",
            "Epoch 165/250\n",
            "19/19 - 0s - loss: 10299.1445 - val_loss: 10890.2197 - 132ms/epoch - 7ms/step\n",
            "Epoch 166/250\n",
            "19/19 - 0s - loss: 10239.3037 - val_loss: 10856.2676 - 137ms/epoch - 7ms/step\n",
            "Epoch 167/250\n",
            "19/19 - 0s - loss: 10191.6650 - val_loss: 10822.1709 - 133ms/epoch - 7ms/step\n",
            "Epoch 168/250\n",
            "19/19 - 0s - loss: 10302.7197 - val_loss: 10787.5322 - 140ms/epoch - 7ms/step\n",
            "Epoch 169/250\n",
            "19/19 - 0s - loss: 10281.7744 - val_loss: 10755.9268 - 160ms/epoch - 8ms/step\n",
            "Epoch 170/250\n",
            "19/19 - 0s - loss: 10286.4307 - val_loss: 10722.5166 - 162ms/epoch - 9ms/step\n",
            "Epoch 171/250\n",
            "19/19 - 0s - loss: 10192.6201 - val_loss: 10691.5205 - 153ms/epoch - 8ms/step\n",
            "Epoch 172/250\n",
            "19/19 - 0s - loss: 10143.9121 - val_loss: 10660.8027 - 153ms/epoch - 8ms/step\n",
            "Epoch 173/250\n",
            "19/19 - 0s - loss: 10056.1992 - val_loss: 10628.2070 - 170ms/epoch - 9ms/step\n",
            "Epoch 174/250\n",
            "19/19 - 0s - loss: 9987.9121 - val_loss: 10599.2148 - 124ms/epoch - 7ms/step\n",
            "Epoch 175/250\n",
            "19/19 - 0s - loss: 10063.6387 - val_loss: 10571.5264 - 112ms/epoch - 6ms/step\n",
            "Epoch 176/250\n",
            "19/19 - 0s - loss: 10039.6035 - val_loss: 10542.0381 - 92ms/epoch - 5ms/step\n",
            "Epoch 177/250\n",
            "19/19 - 0s - loss: 9886.2988 - val_loss: 10513.6074 - 96ms/epoch - 5ms/step\n",
            "Epoch 178/250\n",
            "19/19 - 0s - loss: 10056.4590 - val_loss: 10485.7549 - 96ms/epoch - 5ms/step\n",
            "Epoch 179/250\n",
            "19/19 - 0s - loss: 9895.3740 - val_loss: 10458.9746 - 93ms/epoch - 5ms/step\n",
            "Epoch 180/250\n",
            "19/19 - 0s - loss: 9863.6104 - val_loss: 10431.8984 - 107ms/epoch - 6ms/step\n",
            "Epoch 181/250\n",
            "19/19 - 0s - loss: 9944.3467 - val_loss: 10405.2578 - 94ms/epoch - 5ms/step\n",
            "Epoch 182/250\n",
            "19/19 - 0s - loss: 9818.9746 - val_loss: 10379.2334 - 106ms/epoch - 6ms/step\n",
            "Epoch 183/250\n",
            "19/19 - 0s - loss: 9784.7471 - val_loss: 10352.9619 - 105ms/epoch - 6ms/step\n",
            "Epoch 184/250\n",
            "19/19 - 0s - loss: 9777.1250 - val_loss: 10327.0205 - 105ms/epoch - 6ms/step\n",
            "Epoch 185/250\n",
            "19/19 - 0s - loss: 9774.5596 - val_loss: 10303.3770 - 96ms/epoch - 5ms/step\n",
            "Epoch 186/250\n",
            "19/19 - 0s - loss: 9697.2158 - val_loss: 10277.0664 - 110ms/epoch - 6ms/step\n",
            "Epoch 187/250\n",
            "19/19 - 0s - loss: 9815.2939 - val_loss: 10251.1094 - 93ms/epoch - 5ms/step\n",
            "Epoch 188/250\n",
            "19/19 - 0s - loss: 9638.6523 - val_loss: 10227.3135 - 109ms/epoch - 6ms/step\n",
            "Epoch 189/250\n",
            "19/19 - 0s - loss: 9745.1436 - val_loss: 10206.7041 - 96ms/epoch - 5ms/step\n",
            "Epoch 190/250\n",
            "19/19 - 0s - loss: 9581.6387 - val_loss: 10181.7441 - 110ms/epoch - 6ms/step\n",
            "Epoch 191/250\n",
            "19/19 - 0s - loss: 9644.2510 - val_loss: 10160.7705 - 111ms/epoch - 6ms/step\n",
            "Epoch 192/250\n",
            "19/19 - 0s - loss: 9595.8301 - val_loss: 10139.1719 - 119ms/epoch - 6ms/step\n",
            "Epoch 193/250\n",
            "19/19 - 0s - loss: 9507.1016 - val_loss: 10116.1025 - 92ms/epoch - 5ms/step\n",
            "Epoch 194/250\n",
            "19/19 - 0s - loss: 9609.5459 - val_loss: 10096.3750 - 94ms/epoch - 5ms/step\n",
            "Epoch 195/250\n",
            "19/19 - 0s - loss: 9541.7217 - val_loss: 10074.4541 - 108ms/epoch - 6ms/step\n",
            "Epoch 196/250\n",
            "19/19 - 0s - loss: 9482.3838 - val_loss: 10054.8291 - 99ms/epoch - 5ms/step\n",
            "Epoch 197/250\n",
            "19/19 - 0s - loss: 9342.8350 - val_loss: 10033.9385 - 112ms/epoch - 6ms/step\n",
            "Epoch 198/250\n",
            "19/19 - 0s - loss: 9484.6426 - val_loss: 10014.6953 - 93ms/epoch - 5ms/step\n",
            "Epoch 199/250\n",
            "19/19 - 0s - loss: 9491.2197 - val_loss: 9994.8955 - 107ms/epoch - 6ms/step\n",
            "Epoch 200/250\n",
            "19/19 - 0s - loss: 9306.6963 - val_loss: 9975.9492 - 101ms/epoch - 5ms/step\n",
            "Epoch 201/250\n",
            "19/19 - 0s - loss: 9453.4160 - val_loss: 9956.5967 - 104ms/epoch - 5ms/step\n",
            "Epoch 202/250\n",
            "19/19 - 0s - loss: 9394.0371 - val_loss: 9937.7803 - 92ms/epoch - 5ms/step\n",
            "Epoch 203/250\n",
            "19/19 - 0s - loss: 9425.5752 - val_loss: 9920.4580 - 104ms/epoch - 5ms/step\n",
            "Epoch 204/250\n",
            "19/19 - 0s - loss: 9313.1719 - val_loss: 9902.1426 - 112ms/epoch - 6ms/step\n",
            "Epoch 205/250\n",
            "19/19 - 0s - loss: 9346.4121 - val_loss: 9884.5020 - 107ms/epoch - 6ms/step\n",
            "Epoch 206/250\n",
            "19/19 - 0s - loss: 9341.8291 - val_loss: 9867.5527 - 110ms/epoch - 6ms/step\n",
            "Epoch 207/250\n",
            "19/19 - 0s - loss: 9363.0410 - val_loss: 9850.6680 - 112ms/epoch - 6ms/step\n",
            "Epoch 208/250\n",
            "19/19 - 0s - loss: 9258.2383 - val_loss: 9834.9453 - 109ms/epoch - 6ms/step\n",
            "Epoch 209/250\n",
            "19/19 - 0s - loss: 9223.6865 - val_loss: 9820.2803 - 106ms/epoch - 6ms/step\n",
            "Epoch 210/250\n",
            "19/19 - 0s - loss: 9284.6230 - val_loss: 9804.4990 - 115ms/epoch - 6ms/step\n",
            "Epoch 211/250\n",
            "19/19 - 0s - loss: 9306.7275 - val_loss: 9789.4531 - 109ms/epoch - 6ms/step\n",
            "Epoch 212/250\n",
            "19/19 - 0s - loss: 9193.7471 - val_loss: 9774.9150 - 91ms/epoch - 5ms/step\n",
            "Epoch 213/250\n",
            "19/19 - 0s - loss: 9243.2871 - val_loss: 9760.1631 - 113ms/epoch - 6ms/step\n",
            "Epoch 214/250\n",
            "19/19 - 0s - loss: 9220.8018 - val_loss: 9745.8643 - 108ms/epoch - 6ms/step\n",
            "Epoch 215/250\n",
            "19/19 - 0s - loss: 9206.3018 - val_loss: 9733.1357 - 116ms/epoch - 6ms/step\n",
            "Epoch 216/250\n",
            "19/19 - 0s - loss: 9310.0957 - val_loss: 9719.2041 - 96ms/epoch - 5ms/step\n",
            "Epoch 217/250\n",
            "19/19 - 0s - loss: 9134.3301 - val_loss: 9706.6768 - 101ms/epoch - 5ms/step\n",
            "Epoch 218/250\n",
            "19/19 - 0s - loss: 9147.6201 - val_loss: 9693.7539 - 92ms/epoch - 5ms/step\n",
            "Epoch 219/250\n",
            "19/19 - 0s - loss: 9216.9512 - val_loss: 9682.0400 - 98ms/epoch - 5ms/step\n",
            "Epoch 220/250\n",
            "19/19 - 0s - loss: 9084.3477 - val_loss: 9668.9600 - 118ms/epoch - 6ms/step\n",
            "Epoch 221/250\n",
            "19/19 - 0s - loss: 9169.0811 - val_loss: 9656.2773 - 111ms/epoch - 6ms/step\n",
            "Epoch 222/250\n",
            "19/19 - 0s - loss: 9134.9971 - val_loss: 9644.4492 - 110ms/epoch - 6ms/step\n",
            "Epoch 223/250\n",
            "19/19 - 0s - loss: 9193.2559 - val_loss: 9633.2588 - 116ms/epoch - 6ms/step\n",
            "Epoch 224/250\n",
            "19/19 - 0s - loss: 8901.2529 - val_loss: 9621.9170 - 112ms/epoch - 6ms/step\n",
            "Epoch 225/250\n",
            "19/19 - 0s - loss: 9067.4531 - val_loss: 9611.7139 - 99ms/epoch - 5ms/step\n",
            "Epoch 226/250\n",
            "19/19 - 0s - loss: 9057.8623 - val_loss: 9599.8379 - 110ms/epoch - 6ms/step\n",
            "Epoch 227/250\n",
            "19/19 - 0s - loss: 9099.4004 - val_loss: 9588.8203 - 98ms/epoch - 5ms/step\n",
            "Epoch 228/250\n",
            "19/19 - 0s - loss: 9063.9189 - val_loss: 9579.7822 - 93ms/epoch - 5ms/step\n",
            "Epoch 229/250\n",
            "19/19 - 0s - loss: 9156.8721 - val_loss: 9570.0488 - 113ms/epoch - 6ms/step\n",
            "Epoch 230/250\n",
            "19/19 - 0s - loss: 9168.9375 - val_loss: 9561.1201 - 100ms/epoch - 5ms/step\n",
            "Epoch 231/250\n",
            "19/19 - 0s - loss: 8997.6992 - val_loss: 9551.2119 - 102ms/epoch - 5ms/step\n",
            "Epoch 232/250\n",
            "19/19 - 0s - loss: 9020.9688 - val_loss: 9541.7959 - 108ms/epoch - 6ms/step\n",
            "Epoch 233/250\n",
            "19/19 - 0s - loss: 8912.5195 - val_loss: 9532.5518 - 97ms/epoch - 5ms/step\n",
            "Epoch 234/250\n",
            "19/19 - 0s - loss: 8911.1348 - val_loss: 9524.1104 - 96ms/epoch - 5ms/step\n",
            "Epoch 235/250\n",
            "19/19 - 0s - loss: 9018.4404 - val_loss: 9514.9531 - 116ms/epoch - 6ms/step\n",
            "Epoch 236/250\n",
            "19/19 - 0s - loss: 9002.3945 - val_loss: 9506.5625 - 95ms/epoch - 5ms/step\n",
            "Epoch 237/250\n",
            "19/19 - 0s - loss: 8875.8311 - val_loss: 9498.0137 - 113ms/epoch - 6ms/step\n",
            "Epoch 238/250\n",
            "19/19 - 0s - loss: 9014.5000 - val_loss: 9489.9521 - 95ms/epoch - 5ms/step\n",
            "Epoch 239/250\n",
            "19/19 - 0s - loss: 8971.6816 - val_loss: 9482.5518 - 119ms/epoch - 6ms/step\n",
            "Epoch 240/250\n",
            "19/19 - 0s - loss: 9011.7979 - val_loss: 9475.6387 - 109ms/epoch - 6ms/step\n",
            "Epoch 241/250\n",
            "19/19 - 0s - loss: 8941.2578 - val_loss: 9467.7129 - 108ms/epoch - 6ms/step\n",
            "Epoch 242/250\n",
            "19/19 - 0s - loss: 8914.3438 - val_loss: 9460.6006 - 108ms/epoch - 6ms/step\n",
            "Epoch 243/250\n",
            "19/19 - 0s - loss: 9029.0488 - val_loss: 9453.0469 - 114ms/epoch - 6ms/step\n",
            "Epoch 244/250\n",
            "19/19 - 0s - loss: 8858.8496 - val_loss: 9447.2627 - 99ms/epoch - 5ms/step\n",
            "Epoch 245/250\n",
            "19/19 - 0s - loss: 8830.8672 - val_loss: 9440.1953 - 101ms/epoch - 5ms/step\n",
            "Epoch 246/250\n",
            "19/19 - 0s - loss: 8943.1982 - val_loss: 9433.3398 - 120ms/epoch - 6ms/step\n",
            "Epoch 247/250\n",
            "19/19 - 0s - loss: 8997.1279 - val_loss: 9426.9219 - 106ms/epoch - 6ms/step\n",
            "Epoch 248/250\n",
            "19/19 - 0s - loss: 8855.4336 - val_loss: 9421.0029 - 110ms/epoch - 6ms/step\n",
            "Epoch 249/250\n",
            "19/19 - 0s - loss: 8816.4639 - val_loss: 9415.0684 - 123ms/epoch - 6ms/step\n",
            "Epoch 250/250\n",
            "19/19 - 0s - loss: 8839.8516 - val_loss: 9409.2773 - 117ms/epoch - 6ms/step\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 8038.7358\n",
            "Index: NIFTY, Test MSE: 8038.73583984375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-6d1f8824e18c>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  targets = targets.append(filtered_rows[['high', 'low', 'open', 'close']])\n",
            "<ipython-input-27-6d1f8824e18c>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  targets = targets.append(filtered_rows[['high', 'low', 'open', 'close']])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "19/19 - 5s - loss: 384670.3750 - val_loss: 381595.6250 - 5s/epoch - 276ms/step\n",
            "Epoch 2/250\n",
            "19/19 - 0s - loss: 384500.3438 - val_loss: 381309.1250 - 107ms/epoch - 6ms/step\n",
            "Epoch 3/250\n",
            "19/19 - 0s - loss: 383994.0625 - val_loss: 380431.2188 - 103ms/epoch - 5ms/step\n",
            "Epoch 4/250\n",
            "19/19 - 0s - loss: 382617.6562 - val_loss: 378527.1875 - 97ms/epoch - 5ms/step\n",
            "Epoch 5/250\n",
            "19/19 - 0s - loss: 380363.6250 - val_loss: 376128.9375 - 99ms/epoch - 5ms/step\n",
            "Epoch 6/250\n",
            "19/19 - 0s - loss: 377950.4688 - val_loss: 373993.6562 - 111ms/epoch - 6ms/step\n",
            "Epoch 7/250\n",
            "19/19 - 0s - loss: 376004.4062 - val_loss: 372299.4062 - 98ms/epoch - 5ms/step\n",
            "Epoch 8/250\n",
            "19/19 - 0s - loss: 374504.0312 - val_loss: 370925.2812 - 102ms/epoch - 5ms/step\n",
            "Epoch 9/250\n",
            "19/19 - 0s - loss: 373104.7500 - val_loss: 369716.2500 - 100ms/epoch - 5ms/step\n",
            "Epoch 10/250\n",
            "19/19 - 0s - loss: 371918.4688 - val_loss: 368611.6250 - 115ms/epoch - 6ms/step\n",
            "Epoch 11/250\n",
            "19/19 - 0s - loss: 370817.0625 - val_loss: 367589.8125 - 92ms/epoch - 5ms/step\n",
            "Epoch 12/250\n",
            "19/19 - 0s - loss: 369753.2500 - val_loss: 366610.1875 - 107ms/epoch - 6ms/step\n",
            "Epoch 13/250\n",
            "19/19 - 0s - loss: 368881.0000 - val_loss: 365670.3125 - 107ms/epoch - 6ms/step\n",
            "Epoch 14/250\n",
            "19/19 - 0s - loss: 367832.2500 - val_loss: 364768.8750 - 106ms/epoch - 6ms/step\n",
            "Epoch 15/250\n",
            "19/19 - 0s - loss: 366934.4688 - val_loss: 363876.8750 - 107ms/epoch - 6ms/step\n",
            "Epoch 16/250\n",
            "19/19 - 0s - loss: 366006.2812 - val_loss: 363021.4062 - 96ms/epoch - 5ms/step\n",
            "Epoch 17/250\n",
            "19/19 - 0s - loss: 365194.9062 - val_loss: 362172.4375 - 105ms/epoch - 6ms/step\n",
            "Epoch 18/250\n",
            "19/19 - 0s - loss: 364190.0938 - val_loss: 361333.8750 - 100ms/epoch - 5ms/step\n",
            "Epoch 19/250\n",
            "19/19 - 0s - loss: 363507.1875 - val_loss: 360511.9375 - 108ms/epoch - 6ms/step\n",
            "Epoch 20/250\n",
            "19/19 - 0s - loss: 362540.7812 - val_loss: 359697.7500 - 101ms/epoch - 5ms/step\n",
            "Epoch 21/250\n",
            "19/19 - 0s - loss: 361876.9688 - val_loss: 358906.9062 - 95ms/epoch - 5ms/step\n",
            "Epoch 22/250\n",
            "19/19 - 0s - loss: 361030.8750 - val_loss: 358124.0000 - 92ms/epoch - 5ms/step\n",
            "Epoch 23/250\n",
            "19/19 - 0s - loss: 360147.0625 - val_loss: 357341.5938 - 92ms/epoch - 5ms/step\n",
            "Epoch 24/250\n",
            "19/19 - 0s - loss: 359324.3125 - val_loss: 356553.5625 - 92ms/epoch - 5ms/step\n",
            "Epoch 25/250\n",
            "19/19 - 0s - loss: 358620.6562 - val_loss: 355797.0938 - 92ms/epoch - 5ms/step\n",
            "Epoch 26/250\n",
            "19/19 - 0s - loss: 357860.5312 - val_loss: 355036.8438 - 110ms/epoch - 6ms/step\n",
            "Epoch 27/250\n",
            "19/19 - 0s - loss: 357160.4062 - val_loss: 354273.4062 - 94ms/epoch - 5ms/step\n",
            "Epoch 28/250\n",
            "19/19 - 0s - loss: 356150.7188 - val_loss: 353509.1562 - 110ms/epoch - 6ms/step\n",
            "Epoch 29/250\n",
            "19/19 - 0s - loss: 355365.3125 - val_loss: 352771.1562 - 108ms/epoch - 6ms/step\n",
            "Epoch 30/250\n",
            "19/19 - 0s - loss: 354922.6562 - val_loss: 352041.4375 - 119ms/epoch - 6ms/step\n",
            "Epoch 31/250\n",
            "19/19 - 0s - loss: 354081.3125 - val_loss: 351315.6562 - 109ms/epoch - 6ms/step\n",
            "Epoch 32/250\n",
            "19/19 - 0s - loss: 353265.8438 - val_loss: 350582.2188 - 95ms/epoch - 5ms/step\n",
            "Epoch 33/250\n",
            "19/19 - 0s - loss: 352541.0938 - val_loss: 349850.1875 - 103ms/epoch - 5ms/step\n",
            "Epoch 34/250\n",
            "19/19 - 0s - loss: 351868.6562 - val_loss: 349128.7188 - 94ms/epoch - 5ms/step\n",
            "Epoch 35/250\n",
            "19/19 - 0s - loss: 350878.0312 - val_loss: 348402.3125 - 106ms/epoch - 6ms/step\n",
            "Epoch 36/250\n",
            "19/19 - 0s - loss: 350162.2188 - val_loss: 347680.5312 - 94ms/epoch - 5ms/step\n",
            "Epoch 37/250\n",
            "19/19 - 0s - loss: 349560.3125 - val_loss: 346962.3438 - 96ms/epoch - 5ms/step\n",
            "Epoch 38/250\n",
            "19/19 - 0s - loss: 348740.7188 - val_loss: 346257.5625 - 94ms/epoch - 5ms/step\n",
            "Epoch 39/250\n",
            "19/19 - 0s - loss: 348046.4688 - val_loss: 345558.3438 - 111ms/epoch - 6ms/step\n",
            "Epoch 40/250\n",
            "19/19 - 0s - loss: 347236.4062 - val_loss: 344835.7500 - 116ms/epoch - 6ms/step\n",
            "Epoch 41/250\n",
            "19/19 - 0s - loss: 346585.6562 - val_loss: 344129.3438 - 100ms/epoch - 5ms/step\n",
            "Epoch 42/250\n",
            "19/19 - 0s - loss: 345955.1250 - val_loss: 343438.3750 - 94ms/epoch - 5ms/step\n",
            "Epoch 43/250\n",
            "19/19 - 0s - loss: 345282.1562 - val_loss: 342752.6562 - 95ms/epoch - 5ms/step\n",
            "Epoch 44/250\n",
            "19/19 - 0s - loss: 344440.4062 - val_loss: 342065.3750 - 106ms/epoch - 6ms/step\n",
            "Epoch 45/250\n",
            "19/19 - 0s - loss: 343513.0625 - val_loss: 341375.2188 - 107ms/epoch - 6ms/step\n",
            "Epoch 46/250\n",
            "19/19 - 0s - loss: 343005.0312 - val_loss: 340675.8438 - 110ms/epoch - 6ms/step\n",
            "Epoch 47/250\n",
            "19/19 - 0s - loss: 342587.9375 - val_loss: 339984.0312 - 96ms/epoch - 5ms/step\n",
            "Epoch 48/250\n",
            "19/19 - 0s - loss: 341525.0625 - val_loss: 339313.5312 - 113ms/epoch - 6ms/step\n",
            "Epoch 49/250\n",
            "19/19 - 0s - loss: 340852.4062 - val_loss: 338622.4375 - 120ms/epoch - 6ms/step\n",
            "Epoch 50/250\n",
            "19/19 - 0s - loss: 340475.7188 - val_loss: 337951.4375 - 110ms/epoch - 6ms/step\n",
            "Epoch 51/250\n",
            "19/19 - 0s - loss: 339604.0625 - val_loss: 337277.8125 - 91ms/epoch - 5ms/step\n",
            "Epoch 52/250\n",
            "19/19 - 0s - loss: 339176.7188 - val_loss: 336606.2188 - 89ms/epoch - 5ms/step\n",
            "Epoch 53/250\n",
            "19/19 - 0s - loss: 338117.6250 - val_loss: 335923.6875 - 95ms/epoch - 5ms/step\n",
            "Epoch 54/250\n",
            "19/19 - 0s - loss: 337346.9062 - val_loss: 335259.0938 - 105ms/epoch - 6ms/step\n",
            "Epoch 55/250\n",
            "19/19 - 0s - loss: 336838.3438 - val_loss: 334586.8750 - 91ms/epoch - 5ms/step\n",
            "Epoch 56/250\n",
            "19/19 - 0s - loss: 335897.0625 - val_loss: 333920.2188 - 92ms/epoch - 5ms/step\n",
            "Epoch 57/250\n",
            "19/19 - 0s - loss: 335428.4375 - val_loss: 333255.3438 - 98ms/epoch - 5ms/step\n",
            "Epoch 58/250\n",
            "19/19 - 0s - loss: 334699.6875 - val_loss: 332594.6250 - 90ms/epoch - 5ms/step\n",
            "Epoch 59/250\n",
            "19/19 - 0s - loss: 334327.6875 - val_loss: 331929.8125 - 112ms/epoch - 6ms/step\n",
            "Epoch 60/250\n",
            "19/19 - 0s - loss: 333294.8750 - val_loss: 331281.3438 - 92ms/epoch - 5ms/step\n",
            "Epoch 61/250\n",
            "19/19 - 0s - loss: 332536.9375 - val_loss: 330622.7812 - 107ms/epoch - 6ms/step\n",
            "Epoch 62/250\n",
            "19/19 - 0s - loss: 332120.4375 - val_loss: 329965.5938 - 98ms/epoch - 5ms/step\n",
            "Epoch 63/250\n",
            "19/19 - 0s - loss: 331742.1250 - val_loss: 329307.8125 - 94ms/epoch - 5ms/step\n",
            "Epoch 64/250\n",
            "19/19 - 0s - loss: 330582.6875 - val_loss: 328666.8750 - 94ms/epoch - 5ms/step\n",
            "Epoch 65/250\n",
            "19/19 - 0s - loss: 330008.7188 - val_loss: 328013.2812 - 93ms/epoch - 5ms/step\n",
            "Epoch 66/250\n",
            "19/19 - 0s - loss: 329656.9375 - val_loss: 327364.0000 - 92ms/epoch - 5ms/step\n",
            "Epoch 67/250\n",
            "19/19 - 0s - loss: 328656.9062 - val_loss: 326728.6250 - 107ms/epoch - 6ms/step\n",
            "Epoch 68/250\n",
            "19/19 - 0s - loss: 327703.0312 - val_loss: 326087.9688 - 95ms/epoch - 5ms/step\n",
            "Epoch 69/250\n",
            "19/19 - 0s - loss: 327377.2500 - val_loss: 325437.5938 - 114ms/epoch - 6ms/step\n",
            "Epoch 70/250\n",
            "19/19 - 0s - loss: 326685.3125 - val_loss: 324805.0000 - 97ms/epoch - 5ms/step\n",
            "Epoch 71/250\n",
            "19/19 - 0s - loss: 325841.9062 - val_loss: 324166.4375 - 110ms/epoch - 6ms/step\n",
            "Epoch 72/250\n",
            "19/19 - 0s - loss: 325692.7188 - val_loss: 323532.1250 - 112ms/epoch - 6ms/step\n",
            "Epoch 73/250\n",
            "19/19 - 0s - loss: 324637.1250 - val_loss: 322890.6562 - 95ms/epoch - 5ms/step\n",
            "Epoch 74/250\n",
            "19/19 - 0s - loss: 324009.1250 - val_loss: 322256.3125 - 91ms/epoch - 5ms/step\n",
            "Epoch 75/250\n",
            "19/19 - 0s - loss: 323382.0312 - val_loss: 321630.0625 - 90ms/epoch - 5ms/step\n",
            "Epoch 76/250\n",
            "19/19 - 0s - loss: 322573.2188 - val_loss: 320995.0938 - 98ms/epoch - 5ms/step\n",
            "Epoch 77/250\n",
            "19/19 - 0s - loss: 322253.4375 - val_loss: 320356.9688 - 151ms/epoch - 8ms/step\n",
            "Epoch 78/250\n",
            "19/19 - 0s - loss: 321287.5625 - val_loss: 319738.0938 - 146ms/epoch - 8ms/step\n",
            "Epoch 79/250\n",
            "19/19 - 0s - loss: 320649.9375 - val_loss: 319110.5312 - 141ms/epoch - 7ms/step\n",
            "Epoch 80/250\n",
            "19/19 - 0s - loss: 319984.0312 - val_loss: 318480.3750 - 132ms/epoch - 7ms/step\n",
            "Epoch 81/250\n",
            "19/19 - 0s - loss: 319769.7812 - val_loss: 317857.6562 - 143ms/epoch - 8ms/step\n",
            "Epoch 82/250\n",
            "19/19 - 0s - loss: 319011.9688 - val_loss: 317238.6562 - 144ms/epoch - 8ms/step\n",
            "Epoch 83/250\n",
            "19/19 - 0s - loss: 318206.0312 - val_loss: 316627.9062 - 132ms/epoch - 7ms/step\n",
            "Epoch 84/250\n",
            "19/19 - 0s - loss: 317808.6875 - val_loss: 316009.6562 - 146ms/epoch - 8ms/step\n",
            "Epoch 85/250\n",
            "19/19 - 0s - loss: 317067.1562 - val_loss: 315393.1875 - 142ms/epoch - 7ms/step\n",
            "Epoch 86/250\n",
            "19/19 - 0s - loss: 316335.9375 - val_loss: 314786.2812 - 161ms/epoch - 8ms/step\n",
            "Epoch 87/250\n",
            "19/19 - 0s - loss: 315496.2500 - val_loss: 314170.1250 - 141ms/epoch - 7ms/step\n",
            "Epoch 88/250\n",
            "19/19 - 0s - loss: 315462.8125 - val_loss: 313552.4375 - 156ms/epoch - 8ms/step\n",
            "Epoch 89/250\n",
            "19/19 - 0s - loss: 314049.7812 - val_loss: 312941.4062 - 141ms/epoch - 7ms/step\n",
            "Epoch 90/250\n",
            "19/19 - 0s - loss: 313856.3438 - val_loss: 312337.5000 - 158ms/epoch - 8ms/step\n",
            "Epoch 91/250\n",
            "19/19 - 0s - loss: 312660.4688 - val_loss: 311723.4688 - 132ms/epoch - 7ms/step\n",
            "Epoch 92/250\n",
            "19/19 - 0s - loss: 312279.2188 - val_loss: 311111.2500 - 106ms/epoch - 6ms/step\n",
            "Epoch 93/250\n",
            "19/19 - 0s - loss: 311821.7188 - val_loss: 310512.1250 - 102ms/epoch - 5ms/step\n",
            "Epoch 94/250\n",
            "19/19 - 0s - loss: 311761.3750 - val_loss: 309910.3438 - 91ms/epoch - 5ms/step\n",
            "Epoch 95/250\n",
            "19/19 - 0s - loss: 310514.6875 - val_loss: 309312.5000 - 99ms/epoch - 5ms/step\n",
            "Epoch 96/250\n",
            "19/19 - 0s - loss: 309847.8438 - val_loss: 308714.6875 - 96ms/epoch - 5ms/step\n",
            "Epoch 97/250\n",
            "19/19 - 0s - loss: 309605.2812 - val_loss: 308117.0625 - 108ms/epoch - 6ms/step\n",
            "Epoch 98/250\n",
            "19/19 - 0s - loss: 309398.6250 - val_loss: 307529.0625 - 98ms/epoch - 5ms/step\n",
            "Epoch 99/250\n",
            "19/19 - 0s - loss: 308090.3125 - val_loss: 306932.7812 - 120ms/epoch - 6ms/step\n",
            "Epoch 100/250\n",
            "19/19 - 0s - loss: 307821.5938 - val_loss: 306336.5000 - 117ms/epoch - 6ms/step\n",
            "Epoch 101/250\n",
            "19/19 - 0s - loss: 306413.4375 - val_loss: 305757.4688 - 119ms/epoch - 6ms/step\n",
            "Epoch 102/250\n",
            "19/19 - 0s - loss: 306591.4062 - val_loss: 305157.0625 - 115ms/epoch - 6ms/step\n",
            "Epoch 103/250\n",
            "19/19 - 0s - loss: 306107.2500 - val_loss: 304560.8125 - 105ms/epoch - 6ms/step\n",
            "Epoch 104/250\n",
            "19/19 - 0s - loss: 304701.7812 - val_loss: 303979.5000 - 91ms/epoch - 5ms/step\n",
            "Epoch 105/250\n",
            "19/19 - 0s - loss: 304447.0000 - val_loss: 303383.2188 - 92ms/epoch - 5ms/step\n",
            "Epoch 106/250\n",
            "19/19 - 0s - loss: 303639.6875 - val_loss: 302796.2188 - 92ms/epoch - 5ms/step\n",
            "Epoch 107/250\n",
            "19/19 - 0s - loss: 303619.6250 - val_loss: 302200.4375 - 112ms/epoch - 6ms/step\n",
            "Epoch 108/250\n",
            "19/19 - 0s - loss: 302803.5938 - val_loss: 301619.0312 - 95ms/epoch - 5ms/step\n",
            "Epoch 109/250\n",
            "19/19 - 0s - loss: 302189.6250 - val_loss: 301037.3750 - 96ms/epoch - 5ms/step\n",
            "Epoch 110/250\n",
            "19/19 - 0s - loss: 301313.7812 - val_loss: 300452.1875 - 113ms/epoch - 6ms/step\n",
            "Epoch 111/250\n",
            "19/19 - 0s - loss: 300815.3750 - val_loss: 299873.9062 - 110ms/epoch - 6ms/step\n",
            "Epoch 112/250\n",
            "19/19 - 0s - loss: 300396.5000 - val_loss: 299282.3438 - 116ms/epoch - 6ms/step\n",
            "Epoch 113/250\n",
            "19/19 - 0s - loss: 299482.7188 - val_loss: 298708.9688 - 94ms/epoch - 5ms/step\n",
            "Epoch 114/250\n",
            "19/19 - 0s - loss: 299056.6250 - val_loss: 298135.4062 - 96ms/epoch - 5ms/step\n",
            "Epoch 115/250\n",
            "19/19 - 0s - loss: 298412.4375 - val_loss: 297552.9062 - 92ms/epoch - 5ms/step\n",
            "Epoch 116/250\n",
            "19/19 - 0s - loss: 298369.4375 - val_loss: 296989.6250 - 95ms/epoch - 5ms/step\n",
            "Epoch 117/250\n",
            "19/19 - 0s - loss: 297327.0312 - val_loss: 296411.3750 - 108ms/epoch - 6ms/step\n",
            "Epoch 118/250\n",
            "19/19 - 0s - loss: 296668.8125 - val_loss: 295844.7188 - 107ms/epoch - 6ms/step\n",
            "Epoch 119/250\n",
            "19/19 - 0s - loss: 295833.0000 - val_loss: 295277.8438 - 105ms/epoch - 6ms/step\n",
            "Epoch 120/250\n",
            "19/19 - 0s - loss: 295949.4375 - val_loss: 294708.1250 - 90ms/epoch - 5ms/step\n",
            "Epoch 121/250\n",
            "19/19 - 0s - loss: 295071.5000 - val_loss: 294139.6875 - 110ms/epoch - 6ms/step\n",
            "Epoch 122/250\n",
            "19/19 - 0s - loss: 294553.3438 - val_loss: 293586.5938 - 101ms/epoch - 5ms/step\n",
            "Epoch 123/250\n",
            "19/19 - 0s - loss: 294067.1875 - val_loss: 293015.1250 - 110ms/epoch - 6ms/step\n",
            "Epoch 124/250\n",
            "19/19 - 0s - loss: 293408.7812 - val_loss: 292459.6875 - 111ms/epoch - 6ms/step\n",
            "Epoch 125/250\n",
            "19/19 - 0s - loss: 292698.6562 - val_loss: 291896.2188 - 94ms/epoch - 5ms/step\n",
            "Epoch 126/250\n",
            "19/19 - 0s - loss: 292558.3125 - val_loss: 291336.0938 - 98ms/epoch - 5ms/step\n",
            "Epoch 127/250\n",
            "19/19 - 0s - loss: 291614.0312 - val_loss: 290783.0625 - 114ms/epoch - 6ms/step\n",
            "Epoch 128/250\n",
            "19/19 - 0s - loss: 290996.6250 - val_loss: 290226.2500 - 93ms/epoch - 5ms/step\n",
            "Epoch 129/250\n",
            "19/19 - 0s - loss: 290684.8438 - val_loss: 289659.4062 - 112ms/epoch - 6ms/step\n",
            "Epoch 130/250\n",
            "19/19 - 0s - loss: 289814.0625 - val_loss: 289119.7812 - 107ms/epoch - 6ms/step\n",
            "Epoch 131/250\n",
            "19/19 - 0s - loss: 289644.2188 - val_loss: 288562.2188 - 129ms/epoch - 7ms/step\n",
            "Epoch 132/250\n",
            "19/19 - 0s - loss: 288610.8125 - val_loss: 288009.5312 - 113ms/epoch - 6ms/step\n",
            "Epoch 133/250\n",
            "19/19 - 0s - loss: 288629.4375 - val_loss: 287456.4062 - 98ms/epoch - 5ms/step\n",
            "Epoch 134/250\n",
            "19/19 - 0s - loss: 287594.6562 - val_loss: 286909.4062 - 97ms/epoch - 5ms/step\n",
            "Epoch 135/250\n",
            "19/19 - 0s - loss: 287518.4062 - val_loss: 286372.7500 - 111ms/epoch - 6ms/step\n",
            "Epoch 136/250\n",
            "19/19 - 0s - loss: 286477.9375 - val_loss: 285825.0938 - 101ms/epoch - 5ms/step\n",
            "Epoch 137/250\n",
            "19/19 - 0s - loss: 285508.0000 - val_loss: 285274.8125 - 120ms/epoch - 6ms/step\n",
            "Epoch 138/250\n",
            "19/19 - 0s - loss: 285335.9375 - val_loss: 284715.7812 - 99ms/epoch - 5ms/step\n",
            "Epoch 139/250\n",
            "19/19 - 0s - loss: 284691.1250 - val_loss: 284171.8125 - 111ms/epoch - 6ms/step\n",
            "Epoch 140/250\n",
            "19/19 - 0s - loss: 284219.3750 - val_loss: 283636.3750 - 125ms/epoch - 7ms/step\n",
            "Epoch 141/250\n",
            "19/19 - 0s - loss: 283876.0625 - val_loss: 283090.5312 - 101ms/epoch - 5ms/step\n",
            "Epoch 142/250\n",
            "19/19 - 0s - loss: 282986.3438 - val_loss: 282560.3750 - 97ms/epoch - 5ms/step\n",
            "Epoch 143/250\n",
            "19/19 - 0s - loss: 282379.9375 - val_loss: 282022.6875 - 101ms/epoch - 5ms/step\n",
            "Epoch 144/250\n",
            "19/19 - 0s - loss: 282173.9062 - val_loss: 281483.5000 - 110ms/epoch - 6ms/step\n",
            "Epoch 145/250\n",
            "19/19 - 0s - loss: 281193.3438 - val_loss: 280947.4062 - 96ms/epoch - 5ms/step\n",
            "Epoch 146/250\n",
            "19/19 - 0s - loss: 280947.3438 - val_loss: 280415.5000 - 93ms/epoch - 5ms/step\n",
            "Epoch 147/250\n",
            "19/19 - 0s - loss: 280972.1562 - val_loss: 279876.3125 - 112ms/epoch - 6ms/step\n",
            "Epoch 148/250\n",
            "19/19 - 0s - loss: 280119.2812 - val_loss: 279349.2500 - 90ms/epoch - 5ms/step\n",
            "Epoch 149/250\n",
            "19/19 - 0s - loss: 279393.4688 - val_loss: 278809.9375 - 108ms/epoch - 6ms/step\n",
            "Epoch 150/250\n",
            "19/19 - 0s - loss: 279346.4688 - val_loss: 278284.9062 - 115ms/epoch - 6ms/step\n",
            "Epoch 151/250\n",
            "19/19 - 0s - loss: 277616.8125 - val_loss: 277744.7188 - 96ms/epoch - 5ms/step\n",
            "Epoch 152/250\n",
            "19/19 - 0s - loss: 277437.5312 - val_loss: 277219.7812 - 108ms/epoch - 6ms/step\n",
            "Epoch 153/250\n",
            "19/19 - 0s - loss: 276902.6562 - val_loss: 276688.2188 - 94ms/epoch - 5ms/step\n",
            "Epoch 154/250\n",
            "19/19 - 0s - loss: 276161.6875 - val_loss: 276165.0938 - 98ms/epoch - 5ms/step\n",
            "Epoch 155/250\n",
            "19/19 - 0s - loss: 276695.8125 - val_loss: 275641.3750 - 114ms/epoch - 6ms/step\n",
            "Epoch 156/250\n",
            "19/19 - 0s - loss: 275932.1875 - val_loss: 275116.7188 - 109ms/epoch - 6ms/step\n",
            "Epoch 157/250\n",
            "19/19 - 0s - loss: 274922.1562 - val_loss: 274598.9375 - 97ms/epoch - 5ms/step\n",
            "Epoch 158/250\n",
            "19/19 - 0s - loss: 274638.9375 - val_loss: 274072.7812 - 108ms/epoch - 6ms/step\n",
            "Epoch 159/250\n",
            "19/19 - 0s - loss: 274065.1250 - val_loss: 273560.7188 - 112ms/epoch - 6ms/step\n",
            "Epoch 160/250\n",
            "19/19 - 0s - loss: 273122.1562 - val_loss: 273046.1562 - 105ms/epoch - 6ms/step\n",
            "Epoch 161/250\n",
            "19/19 - 0s - loss: 272465.2188 - val_loss: 272517.4688 - 111ms/epoch - 6ms/step\n",
            "Epoch 162/250\n",
            "19/19 - 0s - loss: 272263.2812 - val_loss: 271995.1562 - 100ms/epoch - 5ms/step\n",
            "Epoch 163/250\n",
            "19/19 - 0s - loss: 271658.3125 - val_loss: 271475.6562 - 99ms/epoch - 5ms/step\n",
            "Epoch 164/250\n",
            "19/19 - 0s - loss: 270738.8750 - val_loss: 270958.7188 - 102ms/epoch - 5ms/step\n",
            "Epoch 165/250\n",
            "19/19 - 0s - loss: 270566.3125 - val_loss: 270447.4062 - 95ms/epoch - 5ms/step\n",
            "Epoch 166/250\n",
            "19/19 - 0s - loss: 270238.8750 - val_loss: 269941.4688 - 107ms/epoch - 6ms/step\n",
            "Epoch 167/250\n",
            "19/19 - 0s - loss: 269838.8750 - val_loss: 269422.7812 - 108ms/epoch - 6ms/step\n",
            "Epoch 168/250\n",
            "19/19 - 0s - loss: 268422.2188 - val_loss: 268915.0938 - 93ms/epoch - 5ms/step\n",
            "Epoch 169/250\n",
            "19/19 - 0s - loss: 268413.3750 - val_loss: 268404.0625 - 100ms/epoch - 5ms/step\n",
            "Epoch 170/250\n",
            "19/19 - 0s - loss: 268012.1875 - val_loss: 267891.0312 - 97ms/epoch - 5ms/step\n",
            "Epoch 171/250\n",
            "19/19 - 0s - loss: 267296.2188 - val_loss: 267379.8438 - 109ms/epoch - 6ms/step\n",
            "Epoch 172/250\n",
            "19/19 - 0s - loss: 267314.4062 - val_loss: 266871.6875 - 94ms/epoch - 5ms/step\n",
            "Epoch 173/250\n",
            "19/19 - 0s - loss: 267085.4375 - val_loss: 266357.8125 - 94ms/epoch - 5ms/step\n",
            "Epoch 174/250\n",
            "19/19 - 0s - loss: 265576.7500 - val_loss: 265857.7188 - 99ms/epoch - 5ms/step\n",
            "Epoch 175/250\n",
            "19/19 - 0s - loss: 265228.5000 - val_loss: 265343.9062 - 116ms/epoch - 6ms/step\n",
            "Epoch 176/250\n",
            "19/19 - 0s - loss: 264651.5312 - val_loss: 264854.0938 - 113ms/epoch - 6ms/step\n",
            "Epoch 177/250\n",
            "19/19 - 0s - loss: 265182.1875 - val_loss: 264348.6250 - 109ms/epoch - 6ms/step\n",
            "Epoch 178/250\n",
            "19/19 - 0s - loss: 263900.0625 - val_loss: 263841.6875 - 94ms/epoch - 5ms/step\n",
            "Epoch 179/250\n",
            "19/19 - 0s - loss: 263010.6250 - val_loss: 263342.5938 - 107ms/epoch - 6ms/step\n",
            "Epoch 180/250\n",
            "19/19 - 0s - loss: 261906.9062 - val_loss: 262838.9062 - 93ms/epoch - 5ms/step\n",
            "Epoch 181/250\n",
            "19/19 - 0s - loss: 262256.8125 - val_loss: 262335.6875 - 98ms/epoch - 5ms/step\n",
            "Epoch 182/250\n",
            "19/19 - 0s - loss: 262171.3438 - val_loss: 261842.6406 - 92ms/epoch - 5ms/step\n",
            "Epoch 183/250\n",
            "19/19 - 0s - loss: 261049.0312 - val_loss: 261346.1250 - 95ms/epoch - 5ms/step\n",
            "Epoch 184/250\n",
            "19/19 - 0s - loss: 261338.1719 - val_loss: 260842.6719 - 119ms/epoch - 6ms/step\n",
            "Epoch 185/250\n",
            "19/19 - 0s - loss: 259634.1719 - val_loss: 260349.2500 - 146ms/epoch - 8ms/step\n",
            "Epoch 186/250\n",
            "19/19 - 0s - loss: 259353.4844 - val_loss: 259847.8125 - 130ms/epoch - 7ms/step\n",
            "Epoch 187/250\n",
            "19/19 - 0s - loss: 258766.4062 - val_loss: 259366.4219 - 141ms/epoch - 7ms/step\n",
            "Epoch 188/250\n",
            "19/19 - 0s - loss: 258420.3906 - val_loss: 258870.7344 - 145ms/epoch - 8ms/step\n",
            "Epoch 189/250\n",
            "19/19 - 0s - loss: 258032.7812 - val_loss: 258371.0312 - 123ms/epoch - 6ms/step\n",
            "Epoch 190/250\n",
            "19/19 - 0s - loss: 256960.1406 - val_loss: 257892.5469 - 132ms/epoch - 7ms/step\n",
            "Epoch 191/250\n",
            "19/19 - 0s - loss: 256516.9375 - val_loss: 257404.0312 - 156ms/epoch - 8ms/step\n",
            "Epoch 192/250\n",
            "19/19 - 0s - loss: 256674.8750 - val_loss: 256917.0625 - 122ms/epoch - 6ms/step\n",
            "Epoch 193/250\n",
            "19/19 - 0s - loss: 256519.7500 - val_loss: 256432.0625 - 132ms/epoch - 7ms/step\n",
            "Epoch 194/250\n",
            "19/19 - 0s - loss: 256256.3594 - val_loss: 255946.6719 - 145ms/epoch - 8ms/step\n",
            "Epoch 195/250\n",
            "19/19 - 0s - loss: 254022.3438 - val_loss: 255466.7500 - 170ms/epoch - 9ms/step\n",
            "Epoch 196/250\n",
            "19/19 - 0s - loss: 254668.0625 - val_loss: 254980.6719 - 164ms/epoch - 9ms/step\n",
            "Epoch 197/250\n",
            "19/19 - 0s - loss: 254410.5469 - val_loss: 254503.5781 - 162ms/epoch - 9ms/step\n",
            "Epoch 198/250\n",
            "19/19 - 0s - loss: 253883.3594 - val_loss: 254026.0000 - 157ms/epoch - 8ms/step\n",
            "Epoch 199/250\n",
            "19/19 - 0s - loss: 253599.7031 - val_loss: 253543.7812 - 142ms/epoch - 7ms/step\n",
            "Epoch 200/250\n",
            "19/19 - 0s - loss: 252685.3906 - val_loss: 253063.5625 - 106ms/epoch - 6ms/step\n",
            "Epoch 201/250\n",
            "19/19 - 0s - loss: 252963.9844 - val_loss: 252595.6875 - 97ms/epoch - 5ms/step\n",
            "Epoch 202/250\n",
            "19/19 - 0s - loss: 251810.3906 - val_loss: 252131.9531 - 103ms/epoch - 5ms/step\n",
            "Epoch 203/250\n",
            "19/19 - 0s - loss: 251086.1875 - val_loss: 251647.1250 - 92ms/epoch - 5ms/step\n",
            "Epoch 204/250\n",
            "19/19 - 0s - loss: 251328.5938 - val_loss: 251171.7969 - 113ms/epoch - 6ms/step\n",
            "Epoch 205/250\n",
            "19/19 - 0s - loss: 250448.7031 - val_loss: 250712.2812 - 95ms/epoch - 5ms/step\n",
            "Epoch 206/250\n",
            "19/19 - 0s - loss: 249584.0000 - val_loss: 250231.7500 - 98ms/epoch - 5ms/step\n",
            "Epoch 207/250\n",
            "19/19 - 0s - loss: 249248.5938 - val_loss: 249760.1562 - 107ms/epoch - 6ms/step\n",
            "Epoch 208/250\n",
            "19/19 - 0s - loss: 248778.6094 - val_loss: 249296.1406 - 95ms/epoch - 5ms/step\n",
            "Epoch 209/250\n",
            "19/19 - 0s - loss: 247597.9062 - val_loss: 248817.4219 - 92ms/epoch - 5ms/step\n",
            "Epoch 210/250\n",
            "19/19 - 0s - loss: 247584.9688 - val_loss: 248346.9844 - 92ms/epoch - 5ms/step\n",
            "Epoch 211/250\n",
            "19/19 - 0s - loss: 247247.1562 - val_loss: 247882.3281 - 111ms/epoch - 6ms/step\n",
            "Epoch 212/250\n",
            "19/19 - 0s - loss: 246895.2969 - val_loss: 247407.0156 - 118ms/epoch - 6ms/step\n",
            "Epoch 213/250\n",
            "19/19 - 0s - loss: 245730.3906 - val_loss: 246949.4688 - 97ms/epoch - 5ms/step\n",
            "Epoch 214/250\n",
            "19/19 - 0s - loss: 246129.1406 - val_loss: 246483.3438 - 107ms/epoch - 6ms/step\n",
            "Epoch 215/250\n",
            "19/19 - 0s - loss: 245529.7344 - val_loss: 246024.0000 - 106ms/epoch - 6ms/step\n",
            "Epoch 216/250\n",
            "19/19 - 0s - loss: 244318.7500 - val_loss: 245565.1406 - 94ms/epoch - 5ms/step\n",
            "Epoch 217/250\n",
            "19/19 - 0s - loss: 244678.0469 - val_loss: 245102.6250 - 106ms/epoch - 6ms/step\n",
            "Epoch 218/250\n",
            "19/19 - 0s - loss: 244125.6094 - val_loss: 244652.7500 - 91ms/epoch - 5ms/step\n",
            "Epoch 219/250\n",
            "19/19 - 0s - loss: 244148.9375 - val_loss: 244198.0781 - 89ms/epoch - 5ms/step\n",
            "Epoch 220/250\n",
            "19/19 - 0s - loss: 243699.7188 - val_loss: 243742.6562 - 91ms/epoch - 5ms/step\n",
            "Epoch 221/250\n",
            "19/19 - 0s - loss: 242833.4688 - val_loss: 243283.5156 - 107ms/epoch - 6ms/step\n",
            "Epoch 222/250\n",
            "19/19 - 0s - loss: 243007.4062 - val_loss: 242829.4219 - 100ms/epoch - 5ms/step\n",
            "Epoch 223/250\n",
            "19/19 - 0s - loss: 241659.1250 - val_loss: 242375.1094 - 114ms/epoch - 6ms/step\n",
            "Epoch 224/250\n",
            "19/19 - 0s - loss: 241317.6719 - val_loss: 241923.3750 - 94ms/epoch - 5ms/step\n",
            "Epoch 225/250\n",
            "19/19 - 0s - loss: 240735.8438 - val_loss: 241478.5469 - 90ms/epoch - 5ms/step\n",
            "Epoch 226/250\n",
            "19/19 - 0s - loss: 240010.4062 - val_loss: 241026.3125 - 97ms/epoch - 5ms/step\n",
            "Epoch 227/250\n",
            "19/19 - 0s - loss: 239612.6719 - val_loss: 240571.2656 - 109ms/epoch - 6ms/step\n",
            "Epoch 228/250\n",
            "19/19 - 0s - loss: 239348.2500 - val_loss: 240122.8750 - 111ms/epoch - 6ms/step\n",
            "Epoch 229/250\n",
            "19/19 - 0s - loss: 238754.3906 - val_loss: 239680.8281 - 93ms/epoch - 5ms/step\n",
            "Epoch 230/250\n",
            "19/19 - 0s - loss: 237997.2656 - val_loss: 239230.4219 - 108ms/epoch - 6ms/step\n",
            "Epoch 231/250\n",
            "19/19 - 0s - loss: 237463.8438 - val_loss: 238783.5469 - 113ms/epoch - 6ms/step\n",
            "Epoch 232/250\n",
            "19/19 - 0s - loss: 236804.4531 - val_loss: 238348.0469 - 103ms/epoch - 5ms/step\n",
            "Epoch 233/250\n",
            "19/19 - 0s - loss: 237101.6719 - val_loss: 237901.3594 - 115ms/epoch - 6ms/step\n",
            "Epoch 234/250\n",
            "19/19 - 0s - loss: 236042.5469 - val_loss: 237456.2812 - 116ms/epoch - 6ms/step\n",
            "Epoch 235/250\n",
            "19/19 - 0s - loss: 236076.1562 - val_loss: 237023.6250 - 115ms/epoch - 6ms/step\n",
            "Epoch 236/250\n",
            "19/19 - 0s - loss: 235436.0938 - val_loss: 236581.6719 - 100ms/epoch - 5ms/step\n",
            "Epoch 237/250\n",
            "19/19 - 0s - loss: 235653.5000 - val_loss: 236140.0000 - 96ms/epoch - 5ms/step\n",
            "Epoch 238/250\n",
            "19/19 - 0s - loss: 234331.3594 - val_loss: 235702.5781 - 96ms/epoch - 5ms/step\n",
            "Epoch 239/250\n",
            "19/19 - 0s - loss: 234206.8125 - val_loss: 235254.1406 - 116ms/epoch - 6ms/step\n",
            "Epoch 240/250\n",
            "19/19 - 0s - loss: 234066.6094 - val_loss: 234823.3594 - 110ms/epoch - 6ms/step\n",
            "Epoch 241/250\n",
            "19/19 - 0s - loss: 233640.2969 - val_loss: 234382.5625 - 121ms/epoch - 6ms/step\n",
            "Epoch 242/250\n",
            "19/19 - 0s - loss: 232789.8906 - val_loss: 233944.4688 - 95ms/epoch - 5ms/step\n",
            "Epoch 243/250\n",
            "19/19 - 0s - loss: 232347.7188 - val_loss: 233495.9844 - 93ms/epoch - 5ms/step\n",
            "Epoch 244/250\n",
            "19/19 - 0s - loss: 231145.0781 - val_loss: 233069.6562 - 110ms/epoch - 6ms/step\n",
            "Epoch 245/250\n",
            "19/19 - 0s - loss: 231736.2188 - val_loss: 232641.6562 - 94ms/epoch - 5ms/step\n",
            "Epoch 246/250\n",
            "19/19 - 0s - loss: 231364.0625 - val_loss: 232202.9062 - 110ms/epoch - 6ms/step\n",
            "Epoch 247/250\n",
            "19/19 - 0s - loss: 231017.5938 - val_loss: 231784.7812 - 95ms/epoch - 5ms/step\n",
            "Epoch 248/250\n",
            "19/19 - 0s - loss: 229946.3125 - val_loss: 231361.5625 - 95ms/epoch - 5ms/step\n",
            "Epoch 249/250\n",
            "19/19 - 0s - loss: 230315.9531 - val_loss: 230938.3594 - 108ms/epoch - 6ms/step\n",
            "Epoch 250/250\n",
            "19/19 - 0s - loss: 228735.7344 - val_loss: 230507.3906 - 109ms/epoch - 6ms/step\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 221000.2969\n",
            "Index: SENSEX, Test MSE: 221000.296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-6d1f8824e18c>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  targets = targets.append(filtered_rows[['high', 'low', 'open', 'close']])\n",
            "<ipython-input-27-6d1f8824e18c>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  targets = targets.append(filtered_rows[['high', 'low', 'open', 'close']])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "18/18 - 4s - loss: 42939.2656 - val_loss: 40441.6914 - 4s/epoch - 228ms/step\n",
            "Epoch 2/250\n",
            "18/18 - 0s - loss: 42888.4648 - val_loss: 40364.9961 - 125ms/epoch - 7ms/step\n",
            "Epoch 3/250\n",
            "18/18 - 0s - loss: 42741.0898 - val_loss: 40144.1406 - 122ms/epoch - 7ms/step\n",
            "Epoch 4/250\n",
            "18/18 - 0s - loss: 42372.7852 - val_loss: 39643.4805 - 139ms/epoch - 8ms/step\n",
            "Epoch 5/250\n",
            "18/18 - 0s - loss: 41685.8672 - val_loss: 38934.1523 - 123ms/epoch - 7ms/step\n",
            "Epoch 6/250\n",
            "18/18 - 0s - loss: 40925.0781 - val_loss: 38228.2852 - 145ms/epoch - 8ms/step\n",
            "Epoch 7/250\n",
            "18/18 - 0s - loss: 40259.6055 - val_loss: 37658.1836 - 120ms/epoch - 7ms/step\n",
            "Epoch 8/250\n",
            "18/18 - 0s - loss: 39709.5469 - val_loss: 37204.4922 - 117ms/epoch - 7ms/step\n",
            "Epoch 9/250\n",
            "18/18 - 0s - loss: 39285.2461 - val_loss: 36821.3633 - 127ms/epoch - 7ms/step\n",
            "Epoch 10/250\n",
            "18/18 - 0s - loss: 38894.9297 - val_loss: 36474.1680 - 142ms/epoch - 8ms/step\n",
            "Epoch 11/250\n",
            "18/18 - 0s - loss: 38555.9688 - val_loss: 36164.0547 - 150ms/epoch - 8ms/step\n",
            "Epoch 12/250\n",
            "18/18 - 0s - loss: 38214.0859 - val_loss: 35872.0938 - 141ms/epoch - 8ms/step\n",
            "Epoch 13/250\n",
            "18/18 - 0s - loss: 37900.0156 - val_loss: 35594.8281 - 132ms/epoch - 7ms/step\n",
            "Epoch 14/250\n",
            "18/18 - 0s - loss: 37626.7383 - val_loss: 35332.0391 - 131ms/epoch - 7ms/step\n",
            "Epoch 15/250\n",
            "18/18 - 0s - loss: 37338.4688 - val_loss: 35071.0391 - 136ms/epoch - 8ms/step\n",
            "Epoch 16/250\n",
            "18/18 - 0s - loss: 37072.3086 - val_loss: 34822.2852 - 100ms/epoch - 6ms/step\n",
            "Epoch 17/250\n",
            "18/18 - 0s - loss: 36821.3438 - val_loss: 34580.3984 - 82ms/epoch - 5ms/step\n",
            "Epoch 18/250\n",
            "18/18 - 0s - loss: 36506.4844 - val_loss: 34344.8242 - 100ms/epoch - 6ms/step\n",
            "Epoch 19/250\n",
            "18/18 - 0s - loss: 36326.4648 - val_loss: 34113.8164 - 84ms/epoch - 5ms/step\n",
            "Epoch 20/250\n",
            "18/18 - 0s - loss: 36061.4648 - val_loss: 33890.7734 - 109ms/epoch - 6ms/step\n",
            "Epoch 21/250\n",
            "18/18 - 0s - loss: 35809.5586 - val_loss: 33668.7422 - 97ms/epoch - 5ms/step\n",
            "Epoch 22/250\n",
            "18/18 - 0s - loss: 35588.5469 - val_loss: 33450.0352 - 101ms/epoch - 6ms/step\n",
            "Epoch 23/250\n",
            "18/18 - 0s - loss: 35352.2969 - val_loss: 33233.8086 - 83ms/epoch - 5ms/step\n",
            "Epoch 24/250\n",
            "18/18 - 0s - loss: 35120.3242 - val_loss: 33023.0898 - 84ms/epoch - 5ms/step\n",
            "Epoch 25/250\n",
            "18/18 - 0s - loss: 34891.0664 - val_loss: 32810.8867 - 94ms/epoch - 5ms/step\n",
            "Epoch 26/250\n",
            "18/18 - 0s - loss: 34716.5625 - val_loss: 32608.0645 - 100ms/epoch - 6ms/step\n",
            "Epoch 27/250\n",
            "18/18 - 0s - loss: 34443.5391 - val_loss: 32407.4004 - 88ms/epoch - 5ms/step\n",
            "Epoch 28/250\n",
            "18/18 - 0s - loss: 34216.3906 - val_loss: 32204.7520 - 100ms/epoch - 6ms/step\n",
            "Epoch 29/250\n",
            "18/18 - 0s - loss: 34038.8672 - val_loss: 32008.7070 - 82ms/epoch - 5ms/step\n",
            "Epoch 30/250\n",
            "18/18 - 0s - loss: 33824.2422 - val_loss: 31811.5957 - 101ms/epoch - 6ms/step\n",
            "Epoch 31/250\n",
            "18/18 - 0s - loss: 33624.7188 - val_loss: 31620.3164 - 109ms/epoch - 6ms/step\n",
            "Epoch 32/250\n",
            "18/18 - 0s - loss: 33400.7695 - val_loss: 31427.1250 - 83ms/epoch - 5ms/step\n",
            "Epoch 33/250\n",
            "18/18 - 0s - loss: 33168.7734 - val_loss: 31237.8125 - 98ms/epoch - 5ms/step\n",
            "Epoch 34/250\n",
            "18/18 - 0s - loss: 32978.3125 - val_loss: 31048.4414 - 84ms/epoch - 5ms/step\n",
            "Epoch 35/250\n",
            "18/18 - 0s - loss: 32789.5977 - val_loss: 30864.9375 - 99ms/epoch - 6ms/step\n",
            "Epoch 36/250\n",
            "18/18 - 0s - loss: 32631.8223 - val_loss: 30680.5332 - 84ms/epoch - 5ms/step\n",
            "Epoch 37/250\n",
            "18/18 - 0s - loss: 32383.6699 - val_loss: 30500.8770 - 99ms/epoch - 5ms/step\n",
            "Epoch 38/250\n",
            "18/18 - 0s - loss: 32133.7266 - val_loss: 30321.1055 - 96ms/epoch - 5ms/step\n",
            "Epoch 39/250\n",
            "18/18 - 0s - loss: 31982.6250 - val_loss: 30140.2793 - 84ms/epoch - 5ms/step\n",
            "Epoch 40/250\n",
            "18/18 - 0s - loss: 31762.3477 - val_loss: 29963.4434 - 98ms/epoch - 5ms/step\n",
            "Epoch 41/250\n",
            "18/18 - 0s - loss: 31686.5703 - val_loss: 29786.1562 - 99ms/epoch - 5ms/step\n",
            "Epoch 42/250\n",
            "18/18 - 0s - loss: 31468.2422 - val_loss: 29616.6699 - 87ms/epoch - 5ms/step\n",
            "Epoch 43/250\n",
            "18/18 - 0s - loss: 31311.5801 - val_loss: 29443.2500 - 83ms/epoch - 5ms/step\n",
            "Epoch 44/250\n",
            "18/18 - 0s - loss: 31020.9902 - val_loss: 29274.5781 - 95ms/epoch - 5ms/step\n",
            "Epoch 45/250\n",
            "18/18 - 0s - loss: 30952.8750 - val_loss: 29107.1152 - 102ms/epoch - 6ms/step\n",
            "Epoch 46/250\n",
            "18/18 - 0s - loss: 30753.4512 - val_loss: 28942.4102 - 98ms/epoch - 5ms/step\n",
            "Epoch 47/250\n",
            "18/18 - 0s - loss: 30476.5625 - val_loss: 28773.6758 - 99ms/epoch - 5ms/step\n",
            "Epoch 48/250\n",
            "18/18 - 0s - loss: 30273.9512 - val_loss: 28610.6309 - 96ms/epoch - 5ms/step\n",
            "Epoch 49/250\n",
            "18/18 - 0s - loss: 30095.8613 - val_loss: 28448.5977 - 101ms/epoch - 6ms/step\n",
            "Epoch 50/250\n",
            "18/18 - 0s - loss: 30053.6836 - val_loss: 28285.6738 - 83ms/epoch - 5ms/step\n",
            "Epoch 51/250\n",
            "18/18 - 0s - loss: 29899.1660 - val_loss: 28124.9141 - 95ms/epoch - 5ms/step\n",
            "Epoch 52/250\n",
            "18/18 - 0s - loss: 29674.8574 - val_loss: 27966.5137 - 106ms/epoch - 6ms/step\n",
            "Epoch 53/250\n",
            "18/18 - 0s - loss: 29510.5098 - val_loss: 27811.3574 - 96ms/epoch - 5ms/step\n",
            "Epoch 54/250\n",
            "18/18 - 0s - loss: 29398.3672 - val_loss: 27655.2344 - 82ms/epoch - 5ms/step\n",
            "Epoch 55/250\n",
            "18/18 - 0s - loss: 29219.7324 - val_loss: 27501.1191 - 95ms/epoch - 5ms/step\n",
            "Epoch 56/250\n",
            "18/18 - 0s - loss: 29020.8730 - val_loss: 27348.2793 - 78ms/epoch - 4ms/step\n",
            "Epoch 57/250\n",
            "18/18 - 0s - loss: 28891.8809 - val_loss: 27198.4219 - 100ms/epoch - 6ms/step\n",
            "Epoch 58/250\n",
            "18/18 - 0s - loss: 28627.1875 - val_loss: 27047.7617 - 99ms/epoch - 6ms/step\n",
            "Epoch 59/250\n",
            "18/18 - 0s - loss: 28461.8164 - val_loss: 26897.8594 - 81ms/epoch - 5ms/step\n",
            "Epoch 60/250\n",
            "18/18 - 0s - loss: 28320.8574 - val_loss: 26749.6973 - 83ms/epoch - 5ms/step\n",
            "Epoch 61/250\n",
            "18/18 - 0s - loss: 28129.5645 - val_loss: 26602.7539 - 86ms/epoch - 5ms/step\n",
            "Epoch 62/250\n",
            "18/18 - 0s - loss: 28011.8906 - val_loss: 26456.1914 - 97ms/epoch - 5ms/step\n",
            "Epoch 63/250\n",
            "18/18 - 0s - loss: 27876.3340 - val_loss: 26312.5488 - 116ms/epoch - 6ms/step\n",
            "Epoch 64/250\n",
            "18/18 - 0s - loss: 27739.4434 - val_loss: 26169.9023 - 83ms/epoch - 5ms/step\n",
            "Epoch 65/250\n",
            "18/18 - 0s - loss: 27447.0645 - val_loss: 26027.8398 - 95ms/epoch - 5ms/step\n",
            "Epoch 66/250\n",
            "18/18 - 0s - loss: 27345.8203 - val_loss: 25884.2500 - 82ms/epoch - 5ms/step\n",
            "Epoch 67/250\n",
            "18/18 - 0s - loss: 27208.7852 - val_loss: 25744.4824 - 99ms/epoch - 5ms/step\n",
            "Epoch 68/250\n",
            "18/18 - 0s - loss: 27129.4180 - val_loss: 25604.3770 - 104ms/epoch - 6ms/step\n",
            "Epoch 69/250\n",
            "18/18 - 0s - loss: 26969.2188 - val_loss: 25467.8945 - 81ms/epoch - 4ms/step\n",
            "Epoch 70/250\n",
            "18/18 - 0s - loss: 26755.4043 - val_loss: 25331.6992 - 94ms/epoch - 5ms/step\n",
            "Epoch 71/250\n",
            "18/18 - 0s - loss: 26572.7148 - val_loss: 25197.1191 - 84ms/epoch - 5ms/step\n",
            "Epoch 72/250\n",
            "18/18 - 0s - loss: 26546.5527 - val_loss: 25066.0625 - 83ms/epoch - 5ms/step\n",
            "Epoch 73/250\n",
            "18/18 - 0s - loss: 26305.6523 - val_loss: 24931.0508 - 90ms/epoch - 5ms/step\n",
            "Epoch 74/250\n",
            "18/18 - 0s - loss: 26255.2988 - val_loss: 24797.5254 - 101ms/epoch - 6ms/step\n",
            "Epoch 75/250\n",
            "18/18 - 0s - loss: 25960.2266 - val_loss: 24667.6328 - 96ms/epoch - 5ms/step\n",
            "Epoch 76/250\n",
            "18/18 - 0s - loss: 25900.8066 - val_loss: 24535.1953 - 100ms/epoch - 6ms/step\n",
            "Epoch 77/250\n",
            "18/18 - 0s - loss: 25817.6641 - val_loss: 24406.3906 - 99ms/epoch - 6ms/step\n",
            "Epoch 78/250\n",
            "18/18 - 0s - loss: 25618.9141 - val_loss: 24280.7383 - 84ms/epoch - 5ms/step\n",
            "Epoch 79/250\n",
            "18/18 - 0s - loss: 25525.8340 - val_loss: 24153.4238 - 81ms/epoch - 5ms/step\n",
            "Epoch 80/250\n",
            "18/18 - 0s - loss: 25411.5898 - val_loss: 24027.4219 - 80ms/epoch - 4ms/step\n",
            "Epoch 81/250\n",
            "18/18 - 0s - loss: 25220.0723 - val_loss: 23903.5332 - 99ms/epoch - 5ms/step\n",
            "Epoch 82/250\n",
            "18/18 - 0s - loss: 25004.9160 - val_loss: 23779.5664 - 106ms/epoch - 6ms/step\n",
            "Epoch 83/250\n",
            "18/18 - 0s - loss: 24917.9922 - val_loss: 23655.7852 - 98ms/epoch - 5ms/step\n",
            "Epoch 84/250\n",
            "18/18 - 0s - loss: 24838.8730 - val_loss: 23535.2266 - 107ms/epoch - 6ms/step\n",
            "Epoch 85/250\n",
            "18/18 - 0s - loss: 24719.0078 - val_loss: 23416.0430 - 81ms/epoch - 4ms/step\n",
            "Epoch 86/250\n",
            "18/18 - 0s - loss: 24489.6113 - val_loss: 23296.7461 - 82ms/epoch - 5ms/step\n",
            "Epoch 87/250\n",
            "18/18 - 0s - loss: 24431.1875 - val_loss: 23177.4297 - 96ms/epoch - 5ms/step\n",
            "Epoch 88/250\n",
            "18/18 - 0s - loss: 24251.2969 - val_loss: 23062.2676 - 97ms/epoch - 5ms/step\n",
            "Epoch 89/250\n",
            "18/18 - 0s - loss: 24213.8086 - val_loss: 22944.5703 - 97ms/epoch - 5ms/step\n",
            "Epoch 90/250\n",
            "18/18 - 0s - loss: 24060.1680 - val_loss: 22829.6426 - 98ms/epoch - 5ms/step\n",
            "Epoch 91/250\n",
            "18/18 - 0s - loss: 23954.1621 - val_loss: 22715.2656 - 107ms/epoch - 6ms/step\n",
            "Epoch 92/250\n",
            "18/18 - 0s - loss: 23769.2637 - val_loss: 22601.2031 - 101ms/epoch - 6ms/step\n",
            "Epoch 93/250\n",
            "18/18 - 0s - loss: 23655.1250 - val_loss: 22487.7324 - 83ms/epoch - 5ms/step\n",
            "Epoch 94/250\n",
            "18/18 - 0s - loss: 23482.7949 - val_loss: 22375.0801 - 103ms/epoch - 6ms/step\n",
            "Epoch 95/250\n",
            "18/18 - 0s - loss: 23337.7266 - val_loss: 22264.0859 - 84ms/epoch - 5ms/step\n",
            "Epoch 96/250\n",
            "18/18 - 0s - loss: 23230.2012 - val_loss: 22153.6035 - 95ms/epoch - 5ms/step\n",
            "Epoch 97/250\n",
            "18/18 - 0s - loss: 23140.9961 - val_loss: 22045.0312 - 96ms/epoch - 5ms/step\n",
            "Epoch 98/250\n",
            "18/18 - 0s - loss: 23110.2109 - val_loss: 21937.2109 - 83ms/epoch - 5ms/step\n",
            "Epoch 99/250\n",
            "18/18 - 0s - loss: 22844.9238 - val_loss: 21830.0391 - 86ms/epoch - 5ms/step\n",
            "Epoch 100/250\n",
            "18/18 - 0s - loss: 22914.3770 - val_loss: 21722.8320 - 83ms/epoch - 5ms/step\n",
            "Epoch 101/250\n",
            "18/18 - 0s - loss: 22641.4160 - val_loss: 21619.3574 - 80ms/epoch - 4ms/step\n",
            "Epoch 102/250\n",
            "18/18 - 0s - loss: 22560.4863 - val_loss: 21514.6660 - 90ms/epoch - 5ms/step\n",
            "Epoch 103/250\n",
            "18/18 - 0s - loss: 22440.3574 - val_loss: 21410.7617 - 83ms/epoch - 5ms/step\n",
            "Epoch 104/250\n",
            "18/18 - 0s - loss: 22467.3105 - val_loss: 21309.8105 - 82ms/epoch - 5ms/step\n",
            "Epoch 105/250\n",
            "18/18 - 0s - loss: 22194.2930 - val_loss: 21205.9160 - 104ms/epoch - 6ms/step\n",
            "Epoch 106/250\n",
            "18/18 - 0s - loss: 22165.8242 - val_loss: 21106.2402 - 85ms/epoch - 5ms/step\n",
            "Epoch 107/250\n",
            "18/18 - 0s - loss: 21994.1211 - val_loss: 21005.4141 - 98ms/epoch - 5ms/step\n",
            "Epoch 108/250\n",
            "18/18 - 0s - loss: 21906.9453 - val_loss: 20905.5566 - 81ms/epoch - 4ms/step\n",
            "Epoch 109/250\n",
            "18/18 - 0s - loss: 21792.5273 - val_loss: 20808.8145 - 86ms/epoch - 5ms/step\n",
            "Epoch 110/250\n",
            "18/18 - 0s - loss: 21603.5020 - val_loss: 20711.2402 - 86ms/epoch - 5ms/step\n",
            "Epoch 111/250\n",
            "18/18 - 0s - loss: 21690.2871 - val_loss: 20616.3047 - 93ms/epoch - 5ms/step\n",
            "Epoch 112/250\n",
            "18/18 - 0s - loss: 21589.0664 - val_loss: 20521.0742 - 85ms/epoch - 5ms/step\n",
            "Epoch 113/250\n",
            "18/18 - 0s - loss: 21301.7461 - val_loss: 20423.5605 - 87ms/epoch - 5ms/step\n",
            "Epoch 114/250\n",
            "18/18 - 0s - loss: 21260.0410 - val_loss: 20330.9316 - 99ms/epoch - 5ms/step\n",
            "Epoch 115/250\n",
            "18/18 - 0s - loss: 21179.5820 - val_loss: 20237.1699 - 83ms/epoch - 5ms/step\n",
            "Epoch 116/250\n",
            "18/18 - 0s - loss: 20984.2344 - val_loss: 20144.4336 - 97ms/epoch - 5ms/step\n",
            "Epoch 117/250\n",
            "18/18 - 0s - loss: 20921.9492 - val_loss: 20048.7656 - 102ms/epoch - 6ms/step\n",
            "Epoch 118/250\n",
            "18/18 - 0s - loss: 20729.5488 - val_loss: 19959.8848 - 96ms/epoch - 5ms/step\n",
            "Epoch 119/250\n",
            "18/18 - 0s - loss: 20704.4727 - val_loss: 19869.1406 - 80ms/epoch - 4ms/step\n",
            "Epoch 120/250\n",
            "18/18 - 0s - loss: 20660.1699 - val_loss: 19781.8730 - 136ms/epoch - 8ms/step\n",
            "Epoch 121/250\n",
            "18/18 - 0s - loss: 20558.9629 - val_loss: 19695.0137 - 137ms/epoch - 8ms/step\n",
            "Epoch 122/250\n",
            "18/18 - 0s - loss: 20403.6660 - val_loss: 19606.3281 - 140ms/epoch - 8ms/step\n",
            "Epoch 123/250\n",
            "18/18 - 0s - loss: 20277.8555 - val_loss: 19520.7500 - 133ms/epoch - 7ms/step\n",
            "Epoch 124/250\n",
            "18/18 - 0s - loss: 20227.2637 - val_loss: 19432.6934 - 137ms/epoch - 8ms/step\n",
            "Epoch 125/250\n",
            "18/18 - 0s - loss: 20125.5039 - val_loss: 19347.8359 - 140ms/epoch - 8ms/step\n",
            "Epoch 126/250\n",
            "18/18 - 0s - loss: 19990.1465 - val_loss: 19264.4746 - 117ms/epoch - 7ms/step\n",
            "Epoch 127/250\n",
            "18/18 - 0s - loss: 19853.6562 - val_loss: 19179.8691 - 125ms/epoch - 7ms/step\n",
            "Epoch 128/250\n",
            "18/18 - 0s - loss: 19999.6777 - val_loss: 19097.1016 - 116ms/epoch - 6ms/step\n",
            "Epoch 129/250\n",
            "18/18 - 0s - loss: 19707.5703 - val_loss: 19013.4238 - 138ms/epoch - 8ms/step\n",
            "Epoch 130/250\n",
            "18/18 - 0s - loss: 19534.9766 - val_loss: 18934.8789 - 149ms/epoch - 8ms/step\n",
            "Epoch 131/250\n",
            "18/18 - 0s - loss: 19586.3574 - val_loss: 18852.3652 - 137ms/epoch - 8ms/step\n",
            "Epoch 132/250\n",
            "18/18 - 0s - loss: 19524.5977 - val_loss: 18773.3945 - 143ms/epoch - 8ms/step\n",
            "Epoch 133/250\n",
            "18/18 - 0s - loss: 19370.8203 - val_loss: 18693.4531 - 143ms/epoch - 8ms/step\n",
            "Epoch 134/250\n",
            "18/18 - 0s - loss: 19360.9023 - val_loss: 18616.4980 - 150ms/epoch - 8ms/step\n",
            "Epoch 135/250\n",
            "18/18 - 0s - loss: 19342.5898 - val_loss: 18538.0488 - 111ms/epoch - 6ms/step\n",
            "Epoch 136/250\n",
            "18/18 - 0s - loss: 19019.2227 - val_loss: 18462.2637 - 87ms/epoch - 5ms/step\n",
            "Epoch 137/250\n",
            "18/18 - 0s - loss: 19046.9062 - val_loss: 18384.7188 - 85ms/epoch - 5ms/step\n",
            "Epoch 138/250\n",
            "18/18 - 0s - loss: 18968.7051 - val_loss: 18309.1758 - 99ms/epoch - 5ms/step\n",
            "Epoch 139/250\n",
            "18/18 - 0s - loss: 18803.1113 - val_loss: 18234.2891 - 85ms/epoch - 5ms/step\n",
            "Epoch 140/250\n",
            "18/18 - 0s - loss: 18739.7188 - val_loss: 18161.1348 - 98ms/epoch - 5ms/step\n",
            "Epoch 141/250\n",
            "18/18 - 0s - loss: 18728.9844 - val_loss: 18088.0234 - 97ms/epoch - 5ms/step\n",
            "Epoch 142/250\n",
            "18/18 - 0s - loss: 18599.4766 - val_loss: 18016.2988 - 97ms/epoch - 5ms/step\n",
            "Epoch 143/250\n",
            "18/18 - 0s - loss: 18382.1699 - val_loss: 17943.6875 - 94ms/epoch - 5ms/step\n",
            "Epoch 144/250\n",
            "18/18 - 0s - loss: 18487.0938 - val_loss: 17874.2715 - 99ms/epoch - 5ms/step\n",
            "Epoch 145/250\n",
            "18/18 - 0s - loss: 18356.9258 - val_loss: 17805.2988 - 87ms/epoch - 5ms/step\n",
            "Epoch 146/250\n",
            "18/18 - 0s - loss: 18354.8398 - val_loss: 17733.2266 - 86ms/epoch - 5ms/step\n",
            "Epoch 147/250\n",
            "18/18 - 0s - loss: 18096.4707 - val_loss: 17665.2539 - 83ms/epoch - 5ms/step\n",
            "Epoch 148/250\n",
            "18/18 - 0s - loss: 18137.6445 - val_loss: 17596.9648 - 96ms/epoch - 5ms/step\n",
            "Epoch 149/250\n",
            "18/18 - 0s - loss: 18254.5391 - val_loss: 17530.4355 - 87ms/epoch - 5ms/step\n",
            "Epoch 150/250\n",
            "18/18 - 0s - loss: 18085.7578 - val_loss: 17465.0312 - 86ms/epoch - 5ms/step\n",
            "Epoch 151/250\n",
            "18/18 - 0s - loss: 17849.5859 - val_loss: 17399.0625 - 96ms/epoch - 5ms/step\n",
            "Epoch 152/250\n",
            "18/18 - 0s - loss: 18020.2637 - val_loss: 17333.9297 - 95ms/epoch - 5ms/step\n",
            "Epoch 153/250\n",
            "18/18 - 0s - loss: 17743.0508 - val_loss: 17268.6719 - 106ms/epoch - 6ms/step\n",
            "Epoch 154/250\n",
            "18/18 - 0s - loss: 17586.3965 - val_loss: 17203.7832 - 95ms/epoch - 5ms/step\n",
            "Epoch 155/250\n",
            "18/18 - 0s - loss: 17565.7734 - val_loss: 17141.8809 - 102ms/epoch - 6ms/step\n",
            "Epoch 156/250\n",
            "18/18 - 0s - loss: 17578.9043 - val_loss: 17079.1855 - 81ms/epoch - 4ms/step\n",
            "Epoch 157/250\n",
            "18/18 - 0s - loss: 17479.2051 - val_loss: 17016.1660 - 98ms/epoch - 5ms/step\n",
            "Epoch 158/250\n",
            "18/18 - 0s - loss: 17409.1621 - val_loss: 16955.0742 - 90ms/epoch - 5ms/step\n",
            "Epoch 159/250\n",
            "18/18 - 0s - loss: 17564.4805 - val_loss: 16896.7969 - 88ms/epoch - 5ms/step\n",
            "Epoch 160/250\n",
            "18/18 - 0s - loss: 17257.2266 - val_loss: 16834.0312 - 83ms/epoch - 5ms/step\n",
            "Epoch 161/250\n",
            "18/18 - 0s - loss: 17165.3574 - val_loss: 16773.8750 - 97ms/epoch - 5ms/step\n",
            "Epoch 162/250\n",
            "18/18 - 0s - loss: 17103.8789 - val_loss: 16717.1602 - 81ms/epoch - 4ms/step\n",
            "Epoch 163/250\n",
            "18/18 - 0s - loss: 17065.7754 - val_loss: 16659.7559 - 99ms/epoch - 5ms/step\n",
            "Epoch 164/250\n",
            "18/18 - 0s - loss: 16920.4805 - val_loss: 16601.9824 - 96ms/epoch - 5ms/step\n",
            "Epoch 165/250\n",
            "18/18 - 0s - loss: 16895.3691 - val_loss: 16545.0059 - 100ms/epoch - 6ms/step\n",
            "Epoch 166/250\n",
            "18/18 - 0s - loss: 16776.5078 - val_loss: 16488.5762 - 99ms/epoch - 5ms/step\n",
            "Epoch 167/250\n",
            "18/18 - 0s - loss: 16739.6133 - val_loss: 16432.9590 - 81ms/epoch - 5ms/step\n",
            "Epoch 168/250\n",
            "18/18 - 0s - loss: 16755.8750 - val_loss: 16379.4043 - 85ms/epoch - 5ms/step\n",
            "Epoch 169/250\n",
            "18/18 - 0s - loss: 16610.2832 - val_loss: 16322.8789 - 82ms/epoch - 5ms/step\n",
            "Epoch 170/250\n",
            "18/18 - 0s - loss: 16631.4531 - val_loss: 16268.9365 - 97ms/epoch - 5ms/step\n",
            "Epoch 171/250\n",
            "18/18 - 0s - loss: 16555.8047 - val_loss: 16215.2080 - 102ms/epoch - 6ms/step\n",
            "Epoch 172/250\n",
            "18/18 - 0s - loss: 16597.3027 - val_loss: 16164.4111 - 86ms/epoch - 5ms/step\n",
            "Epoch 173/250\n",
            "18/18 - 0s - loss: 16331.9707 - val_loss: 16111.9180 - 103ms/epoch - 6ms/step\n",
            "Epoch 174/250\n",
            "18/18 - 0s - loss: 16333.9111 - val_loss: 16060.3604 - 109ms/epoch - 6ms/step\n",
            "Epoch 175/250\n",
            "18/18 - 0s - loss: 16485.5410 - val_loss: 16009.6426 - 85ms/epoch - 5ms/step\n",
            "Epoch 176/250\n",
            "18/18 - 0s - loss: 16129.6582 - val_loss: 15958.8369 - 100ms/epoch - 6ms/step\n",
            "Epoch 177/250\n",
            "18/18 - 0s - loss: 16113.5400 - val_loss: 15909.7295 - 94ms/epoch - 5ms/step\n",
            "Epoch 178/250\n",
            "18/18 - 0s - loss: 16105.5068 - val_loss: 15860.5029 - 81ms/epoch - 5ms/step\n",
            "Epoch 179/250\n",
            "18/18 - 0s - loss: 16161.4336 - val_loss: 15814.0215 - 82ms/epoch - 5ms/step\n",
            "Epoch 180/250\n",
            "18/18 - 0s - loss: 15962.6357 - val_loss: 15766.0527 - 102ms/epoch - 6ms/step\n",
            "Epoch 181/250\n",
            "18/18 - 0s - loss: 15977.9287 - val_loss: 15718.4561 - 114ms/epoch - 6ms/step\n",
            "Epoch 182/250\n",
            "18/18 - 0s - loss: 15919.3506 - val_loss: 15672.6250 - 87ms/epoch - 5ms/step\n",
            "Epoch 183/250\n",
            "18/18 - 0s - loss: 15818.2100 - val_loss: 15626.0342 - 99ms/epoch - 6ms/step\n",
            "Epoch 184/250\n",
            "18/18 - 0s - loss: 15703.5312 - val_loss: 15580.8018 - 97ms/epoch - 5ms/step\n",
            "Epoch 185/250\n",
            "18/18 - 0s - loss: 15838.8457 - val_loss: 15534.8623 - 99ms/epoch - 6ms/step\n",
            "Epoch 186/250\n",
            "18/18 - 0s - loss: 15597.4600 - val_loss: 15489.2930 - 83ms/epoch - 5ms/step\n",
            "Epoch 187/250\n",
            "18/18 - 0s - loss: 15680.9727 - val_loss: 15446.4443 - 84ms/epoch - 5ms/step\n",
            "Epoch 188/250\n",
            "18/18 - 0s - loss: 15603.4707 - val_loss: 15402.5898 - 80ms/epoch - 4ms/step\n",
            "Epoch 189/250\n",
            "18/18 - 0s - loss: 15423.5195 - val_loss: 15359.9492 - 94ms/epoch - 5ms/step\n",
            "Epoch 190/250\n",
            "18/18 - 0s - loss: 15394.7656 - val_loss: 15317.3662 - 83ms/epoch - 5ms/step\n",
            "Epoch 191/250\n",
            "18/18 - 0s - loss: 15488.8086 - val_loss: 15275.7129 - 97ms/epoch - 5ms/step\n",
            "Epoch 192/250\n",
            "18/18 - 0s - loss: 15340.1631 - val_loss: 15234.9961 - 86ms/epoch - 5ms/step\n",
            "Epoch 193/250\n",
            "18/18 - 0s - loss: 15342.6201 - val_loss: 15193.6826 - 85ms/epoch - 5ms/step\n",
            "Epoch 194/250\n",
            "18/18 - 0s - loss: 15139.8818 - val_loss: 15154.5010 - 95ms/epoch - 5ms/step\n",
            "Epoch 195/250\n",
            "18/18 - 0s - loss: 15244.6582 - val_loss: 15114.1494 - 95ms/epoch - 5ms/step\n",
            "Epoch 196/250\n",
            "18/18 - 0s - loss: 15118.4199 - val_loss: 15074.1719 - 85ms/epoch - 5ms/step\n",
            "Epoch 197/250\n",
            "18/18 - 0s - loss: 14828.7832 - val_loss: 15034.5879 - 94ms/epoch - 5ms/step\n",
            "Epoch 198/250\n",
            "18/18 - 0s - loss: 15027.6113 - val_loss: 14997.1523 - 84ms/epoch - 5ms/step\n",
            "Epoch 199/250\n",
            "18/18 - 0s - loss: 14976.9912 - val_loss: 14959.5352 - 106ms/epoch - 6ms/step\n",
            "Epoch 200/250\n",
            "18/18 - 0s - loss: 15069.0469 - val_loss: 14922.1172 - 88ms/epoch - 5ms/step\n",
            "Epoch 201/250\n",
            "18/18 - 0s - loss: 14965.1025 - val_loss: 14886.1650 - 92ms/epoch - 5ms/step\n",
            "Epoch 202/250\n",
            "18/18 - 0s - loss: 14804.5244 - val_loss: 14849.7031 - 102ms/epoch - 6ms/step\n",
            "Epoch 203/250\n",
            "18/18 - 0s - loss: 14919.9688 - val_loss: 14813.3291 - 85ms/epoch - 5ms/step\n",
            "Epoch 204/250\n",
            "18/18 - 0s - loss: 14896.9932 - val_loss: 14779.8271 - 91ms/epoch - 5ms/step\n",
            "Epoch 205/250\n",
            "18/18 - 0s - loss: 14608.4062 - val_loss: 14745.7109 - 91ms/epoch - 5ms/step\n",
            "Epoch 206/250\n",
            "18/18 - 0s - loss: 14835.3232 - val_loss: 14710.1787 - 110ms/epoch - 6ms/step\n",
            "Epoch 207/250\n",
            "18/18 - 0s - loss: 14728.0732 - val_loss: 14676.6729 - 106ms/epoch - 6ms/step\n",
            "Epoch 208/250\n",
            "18/18 - 0s - loss: 14716.4014 - val_loss: 14642.6494 - 106ms/epoch - 6ms/step\n",
            "Epoch 209/250\n",
            "18/18 - 0s - loss: 14587.3018 - val_loss: 14610.6182 - 110ms/epoch - 6ms/step\n",
            "Epoch 210/250\n",
            "18/18 - 0s - loss: 14398.9648 - val_loss: 14578.5498 - 106ms/epoch - 6ms/step\n",
            "Epoch 211/250\n",
            "18/18 - 0s - loss: 14548.4883 - val_loss: 14547.9072 - 106ms/epoch - 6ms/step\n",
            "Epoch 212/250\n",
            "18/18 - 0s - loss: 14454.0352 - val_loss: 14514.9756 - 97ms/epoch - 5ms/step\n",
            "Epoch 213/250\n",
            "18/18 - 0s - loss: 14419.1250 - val_loss: 14484.3682 - 92ms/epoch - 5ms/step\n",
            "Epoch 214/250\n",
            "18/18 - 0s - loss: 14398.6279 - val_loss: 14454.0059 - 85ms/epoch - 5ms/step\n",
            "Epoch 215/250\n",
            "18/18 - 0s - loss: 14451.4268 - val_loss: 14424.9463 - 84ms/epoch - 5ms/step\n",
            "Epoch 216/250\n",
            "18/18 - 0s - loss: 14591.0801 - val_loss: 14395.0273 - 97ms/epoch - 5ms/step\n",
            "Epoch 217/250\n",
            "18/18 - 0s - loss: 14296.4971 - val_loss: 14365.0273 - 97ms/epoch - 5ms/step\n",
            "Epoch 218/250\n",
            "18/18 - 0s - loss: 14397.5889 - val_loss: 14337.6826 - 84ms/epoch - 5ms/step\n",
            "Epoch 219/250\n",
            "18/18 - 0s - loss: 14041.4463 - val_loss: 14309.9395 - 92ms/epoch - 5ms/step\n",
            "Epoch 220/250\n",
            "18/18 - 0s - loss: 14306.7598 - val_loss: 14282.6387 - 93ms/epoch - 5ms/step\n",
            "Epoch 221/250\n",
            "18/18 - 0s - loss: 14098.4736 - val_loss: 14255.5332 - 98ms/epoch - 5ms/step\n",
            "Epoch 222/250\n",
            "18/18 - 0s - loss: 14129.5586 - val_loss: 14227.7471 - 99ms/epoch - 5ms/step\n",
            "Epoch 223/250\n",
            "18/18 - 0s - loss: 14037.7969 - val_loss: 14201.3340 - 89ms/epoch - 5ms/step\n",
            "Epoch 224/250\n",
            "18/18 - 0s - loss: 14202.4082 - val_loss: 14175.8486 - 88ms/epoch - 5ms/step\n",
            "Epoch 225/250\n",
            "18/18 - 0s - loss: 13994.5273 - val_loss: 14149.7119 - 89ms/epoch - 5ms/step\n",
            "Epoch 226/250\n",
            "18/18 - 0s - loss: 14021.3691 - val_loss: 14124.9678 - 88ms/epoch - 5ms/step\n",
            "Epoch 227/250\n",
            "18/18 - 0s - loss: 13929.5771 - val_loss: 14101.4434 - 95ms/epoch - 5ms/step\n",
            "Epoch 228/250\n",
            "18/18 - 0s - loss: 13798.7139 - val_loss: 14076.7910 - 100ms/epoch - 6ms/step\n",
            "Epoch 229/250\n",
            "18/18 - 0s - loss: 13943.3018 - val_loss: 14053.0068 - 93ms/epoch - 5ms/step\n",
            "Epoch 230/250\n",
            "18/18 - 0s - loss: 13775.9404 - val_loss: 14029.8877 - 95ms/epoch - 5ms/step\n",
            "Epoch 231/250\n",
            "18/18 - 0s - loss: 13900.6582 - val_loss: 14006.1553 - 89ms/epoch - 5ms/step\n",
            "Epoch 232/250\n",
            "18/18 - 0s - loss: 13937.2266 - val_loss: 13984.9590 - 104ms/epoch - 6ms/step\n",
            "Epoch 233/250\n",
            "18/18 - 0s - loss: 13754.1768 - val_loss: 13961.3184 - 90ms/epoch - 5ms/step\n",
            "Epoch 234/250\n",
            "18/18 - 0s - loss: 13740.7021 - val_loss: 13938.5186 - 84ms/epoch - 5ms/step\n",
            "Epoch 235/250\n",
            "18/18 - 0s - loss: 13657.1582 - val_loss: 13917.0977 - 101ms/epoch - 6ms/step\n",
            "Epoch 236/250\n",
            "18/18 - 0s - loss: 13677.9336 - val_loss: 13896.4678 - 88ms/epoch - 5ms/step\n",
            "Epoch 237/250\n",
            "18/18 - 0s - loss: 13673.5967 - val_loss: 13876.3564 - 108ms/epoch - 6ms/step\n",
            "Epoch 238/250\n",
            "18/18 - 0s - loss: 13625.5898 - val_loss: 13856.0898 - 115ms/epoch - 6ms/step\n",
            "Epoch 239/250\n",
            "18/18 - 0s - loss: 13466.2109 - val_loss: 13834.1670 - 128ms/epoch - 7ms/step\n",
            "Epoch 240/250\n",
            "18/18 - 0s - loss: 13554.7744 - val_loss: 13814.8633 - 137ms/epoch - 8ms/step\n",
            "Epoch 241/250\n",
            "18/18 - 0s - loss: 13481.5146 - val_loss: 13796.1875 - 161ms/epoch - 9ms/step\n",
            "Epoch 242/250\n",
            "18/18 - 0s - loss: 13491.2490 - val_loss: 13775.5352 - 167ms/epoch - 9ms/step\n",
            "Epoch 243/250\n",
            "18/18 - 0s - loss: 13480.6523 - val_loss: 13757.3516 - 161ms/epoch - 9ms/step\n",
            "Epoch 244/250\n",
            "18/18 - 0s - loss: 13439.1953 - val_loss: 13739.0938 - 220ms/epoch - 12ms/step\n",
            "Epoch 245/250\n",
            "18/18 - 0s - loss: 13211.6484 - val_loss: 13721.5547 - 149ms/epoch - 8ms/step\n",
            "Epoch 246/250\n",
            "18/18 - 0s - loss: 13483.4023 - val_loss: 13704.4453 - 155ms/epoch - 9ms/step\n",
            "Epoch 247/250\n",
            "18/18 - 0s - loss: 13362.6445 - val_loss: 13687.2500 - 154ms/epoch - 9ms/step\n",
            "Epoch 248/250\n",
            "18/18 - 0s - loss: 13462.2139 - val_loss: 13670.6025 - 162ms/epoch - 9ms/step\n",
            "Epoch 249/250\n",
            "18/18 - 0s - loss: 13503.9297 - val_loss: 13654.1689 - 148ms/epoch - 8ms/step\n",
            "Epoch 250/250\n",
            "18/18 - 0s - loss: 13370.6758 - val_loss: 13637.6230 - 131ms/epoch - 7ms/step\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 13224.7598\n",
            "Index: FINNIFTY, Test MSE: 13224.759765625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-6d1f8824e18c>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  targets = targets.append(filtered_rows[['high', 'low', 'open', 'close']])\n",
            "<ipython-input-27-6d1f8824e18c>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  targets = targets.append(filtered_rows[['high', 'low', 'open', 'close']])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "12/12 - 6s - loss: 415477.9375 - val_loss: 419836.1562 - 6s/epoch - 480ms/step\n",
            "Epoch 2/250\n",
            "12/12 - 0s - loss: 415412.2812 - val_loss: 419750.3438 - 74ms/epoch - 6ms/step\n",
            "Epoch 3/250\n",
            "12/12 - 0s - loss: 415300.3125 - val_loss: 419575.3125 - 92ms/epoch - 8ms/step\n",
            "Epoch 4/250\n",
            "12/12 - 0s - loss: 415044.0938 - val_loss: 419193.7812 - 94ms/epoch - 8ms/step\n",
            "Epoch 5/250\n",
            "12/12 - 0s - loss: 414520.0312 - val_loss: 418426.9688 - 89ms/epoch - 7ms/step\n",
            "Epoch 6/250\n",
            "12/12 - 0s - loss: 413554.3125 - val_loss: 417165.8750 - 79ms/epoch - 7ms/step\n",
            "Epoch 7/250\n",
            "12/12 - 0s - loss: 412110.6562 - val_loss: 415559.1875 - 88ms/epoch - 7ms/step\n",
            "Epoch 8/250\n",
            "12/12 - 0s - loss: 410534.6875 - val_loss: 413914.0000 - 71ms/epoch - 6ms/step\n",
            "Epoch 9/250\n",
            "12/12 - 0s - loss: 408948.4688 - val_loss: 412381.0625 - 75ms/epoch - 6ms/step\n",
            "Epoch 10/250\n",
            "12/12 - 0s - loss: 407592.6875 - val_loss: 411073.6250 - 94ms/epoch - 8ms/step\n",
            "Epoch 11/250\n",
            "12/12 - 0s - loss: 406375.8750 - val_loss: 409934.8125 - 93ms/epoch - 8ms/step\n",
            "Epoch 12/250\n",
            "12/12 - 0s - loss: 405343.2812 - val_loss: 408914.7188 - 91ms/epoch - 8ms/step\n",
            "Epoch 13/250\n",
            "12/12 - 0s - loss: 404396.6250 - val_loss: 408007.4375 - 91ms/epoch - 8ms/step\n",
            "Epoch 14/250\n",
            "12/12 - 0s - loss: 403544.1562 - val_loss: 407175.0938 - 93ms/epoch - 8ms/step\n",
            "Epoch 15/250\n",
            "12/12 - 0s - loss: 402684.8750 - val_loss: 406376.2188 - 80ms/epoch - 7ms/step\n",
            "Epoch 16/250\n",
            "12/12 - 0s - loss: 402179.4375 - val_loss: 405630.3125 - 96ms/epoch - 8ms/step\n",
            "Epoch 17/250\n",
            "12/12 - 0s - loss: 401227.4062 - val_loss: 404917.6562 - 75ms/epoch - 6ms/step\n",
            "Epoch 18/250\n",
            "12/12 - 0s - loss: 400491.1875 - val_loss: 404216.6562 - 73ms/epoch - 6ms/step\n",
            "Epoch 19/250\n",
            "12/12 - 0s - loss: 399999.1875 - val_loss: 403540.4062 - 73ms/epoch - 6ms/step\n",
            "Epoch 20/250\n",
            "12/12 - 0s - loss: 399241.3438 - val_loss: 402884.9375 - 87ms/epoch - 7ms/step\n",
            "Epoch 21/250\n",
            "12/12 - 0s - loss: 398552.8750 - val_loss: 402234.9062 - 75ms/epoch - 6ms/step\n",
            "Epoch 22/250\n",
            "12/12 - 0s - loss: 397996.6562 - val_loss: 401612.3125 - 74ms/epoch - 6ms/step\n",
            "Epoch 23/250\n",
            "12/12 - 0s - loss: 397396.0625 - val_loss: 400989.4375 - 74ms/epoch - 6ms/step\n",
            "Epoch 24/250\n",
            "12/12 - 0s - loss: 396692.1562 - val_loss: 400378.0625 - 83ms/epoch - 7ms/step\n",
            "Epoch 25/250\n",
            "12/12 - 0s - loss: 396156.5625 - val_loss: 399778.3438 - 90ms/epoch - 7ms/step\n",
            "Epoch 26/250\n",
            "12/12 - 0s - loss: 395565.0938 - val_loss: 399179.5000 - 97ms/epoch - 8ms/step\n",
            "Epoch 27/250\n",
            "12/12 - 0s - loss: 395114.0312 - val_loss: 398598.8125 - 84ms/epoch - 7ms/step\n",
            "Epoch 28/250\n",
            "12/12 - 0s - loss: 394443.6875 - val_loss: 398020.4375 - 76ms/epoch - 6ms/step\n",
            "Epoch 29/250\n",
            "12/12 - 0s - loss: 393865.2812 - val_loss: 397449.0625 - 74ms/epoch - 6ms/step\n",
            "Epoch 30/250\n",
            "12/12 - 0s - loss: 393278.6250 - val_loss: 396871.1875 - 78ms/epoch - 6ms/step\n",
            "Epoch 31/250\n",
            "12/12 - 0s - loss: 392895.6562 - val_loss: 396300.5625 - 88ms/epoch - 7ms/step\n",
            "Epoch 32/250\n",
            "12/12 - 0s - loss: 392244.8125 - val_loss: 395738.5625 - 73ms/epoch - 6ms/step\n",
            "Epoch 33/250\n",
            "12/12 - 0s - loss: 391710.0000 - val_loss: 395179.3125 - 79ms/epoch - 7ms/step\n",
            "Epoch 34/250\n",
            "12/12 - 0s - loss: 391168.1875 - val_loss: 394623.3125 - 76ms/epoch - 6ms/step\n",
            "Epoch 35/250\n",
            "12/12 - 0s - loss: 390598.1875 - val_loss: 394069.9375 - 76ms/epoch - 6ms/step\n",
            "Epoch 36/250\n",
            "12/12 - 0s - loss: 390199.2500 - val_loss: 393510.1875 - 90ms/epoch - 7ms/step\n",
            "Epoch 37/250\n",
            "12/12 - 0s - loss: 389682.1250 - val_loss: 392965.8438 - 81ms/epoch - 7ms/step\n",
            "Epoch 38/250\n",
            "12/12 - 0s - loss: 388947.3125 - val_loss: 392422.6875 - 78ms/epoch - 6ms/step\n",
            "Epoch 39/250\n",
            "12/12 - 0s - loss: 388304.2812 - val_loss: 391881.4688 - 86ms/epoch - 7ms/step\n",
            "Epoch 40/250\n",
            "12/12 - 0s - loss: 387957.2188 - val_loss: 391344.2188 - 91ms/epoch - 8ms/step\n",
            "Epoch 41/250\n",
            "12/12 - 0s - loss: 387183.0312 - val_loss: 390801.8438 - 95ms/epoch - 8ms/step\n",
            "Epoch 42/250\n",
            "12/12 - 0s - loss: 386700.0000 - val_loss: 390275.2812 - 91ms/epoch - 8ms/step\n",
            "Epoch 43/250\n",
            "12/12 - 0s - loss: 386451.5625 - val_loss: 389751.0625 - 91ms/epoch - 8ms/step\n",
            "Epoch 44/250\n",
            "12/12 - 0s - loss: 386137.1875 - val_loss: 389227.1875 - 72ms/epoch - 6ms/step\n",
            "Epoch 45/250\n",
            "12/12 - 0s - loss: 385462.0938 - val_loss: 388712.7500 - 89ms/epoch - 7ms/step\n",
            "Epoch 46/250\n",
            "12/12 - 0s - loss: 384732.8750 - val_loss: 388202.3750 - 75ms/epoch - 6ms/step\n",
            "Epoch 47/250\n",
            "12/12 - 0s - loss: 384476.4688 - val_loss: 387690.5625 - 91ms/epoch - 8ms/step\n",
            "Epoch 48/250\n",
            "12/12 - 0s - loss: 383873.0312 - val_loss: 387166.5625 - 96ms/epoch - 8ms/step\n",
            "Epoch 49/250\n",
            "12/12 - 0s - loss: 383254.8750 - val_loss: 386655.4062 - 75ms/epoch - 6ms/step\n",
            "Epoch 50/250\n",
            "12/12 - 0s - loss: 382711.7500 - val_loss: 386139.8438 - 75ms/epoch - 6ms/step\n",
            "Epoch 51/250\n",
            "12/12 - 0s - loss: 382491.7812 - val_loss: 385618.3750 - 105ms/epoch - 9ms/step\n",
            "Epoch 52/250\n",
            "12/12 - 0s - loss: 381495.1250 - val_loss: 385102.7500 - 116ms/epoch - 10ms/step\n",
            "Epoch 53/250\n",
            "12/12 - 0s - loss: 381442.3125 - val_loss: 384594.2812 - 128ms/epoch - 11ms/step\n",
            "Epoch 54/250\n",
            "12/12 - 0s - loss: 380769.2500 - val_loss: 384087.3750 - 126ms/epoch - 11ms/step\n",
            "Epoch 55/250\n",
            "12/12 - 0s - loss: 380139.6250 - val_loss: 383567.3125 - 97ms/epoch - 8ms/step\n",
            "Epoch 56/250\n",
            "12/12 - 0s - loss: 379743.4688 - val_loss: 383070.5625 - 113ms/epoch - 9ms/step\n",
            "Epoch 57/250\n",
            "12/12 - 0s - loss: 379244.1562 - val_loss: 382573.3438 - 108ms/epoch - 9ms/step\n",
            "Epoch 58/250\n",
            "12/12 - 0s - loss: 378785.5000 - val_loss: 382061.0000 - 112ms/epoch - 9ms/step\n",
            "Epoch 59/250\n",
            "12/12 - 0s - loss: 378316.6562 - val_loss: 381565.2500 - 130ms/epoch - 11ms/step\n",
            "Epoch 60/250\n",
            "12/12 - 0s - loss: 377924.5938 - val_loss: 381066.2500 - 124ms/epoch - 10ms/step\n",
            "Epoch 61/250\n",
            "12/12 - 0s - loss: 377465.4375 - val_loss: 380566.3750 - 120ms/epoch - 10ms/step\n",
            "Epoch 62/250\n",
            "12/12 - 0s - loss: 376819.9375 - val_loss: 380057.9375 - 121ms/epoch - 10ms/step\n",
            "Epoch 63/250\n",
            "12/12 - 0s - loss: 376569.8125 - val_loss: 379570.4062 - 101ms/epoch - 8ms/step\n",
            "Epoch 64/250\n",
            "12/12 - 0s - loss: 376089.0938 - val_loss: 379080.3438 - 104ms/epoch - 9ms/step\n",
            "Epoch 65/250\n",
            "12/12 - 0s - loss: 375403.5000 - val_loss: 378580.1875 - 112ms/epoch - 9ms/step\n",
            "Epoch 66/250\n",
            "12/12 - 0s - loss: 374971.4688 - val_loss: 378095.8438 - 120ms/epoch - 10ms/step\n",
            "Epoch 67/250\n",
            "12/12 - 0s - loss: 374679.4062 - val_loss: 377613.6250 - 121ms/epoch - 10ms/step\n",
            "Epoch 68/250\n",
            "12/12 - 0s - loss: 374061.3750 - val_loss: 377116.2188 - 144ms/epoch - 12ms/step\n",
            "Epoch 69/250\n",
            "12/12 - 0s - loss: 373492.1562 - val_loss: 376624.5312 - 77ms/epoch - 6ms/step\n",
            "Epoch 70/250\n",
            "12/12 - 0s - loss: 372963.5000 - val_loss: 376140.8125 - 74ms/epoch - 6ms/step\n",
            "Epoch 71/250\n",
            "12/12 - 0s - loss: 372709.0000 - val_loss: 375646.6562 - 74ms/epoch - 6ms/step\n",
            "Epoch 72/250\n",
            "12/12 - 0s - loss: 372027.2188 - val_loss: 375163.9688 - 74ms/epoch - 6ms/step\n",
            "Epoch 73/250\n",
            "12/12 - 0s - loss: 371502.3438 - val_loss: 374670.1562 - 76ms/epoch - 6ms/step\n",
            "Epoch 74/250\n",
            "12/12 - 0s - loss: 371041.7500 - val_loss: 374174.5000 - 93ms/epoch - 8ms/step\n",
            "Epoch 75/250\n",
            "12/12 - 0s - loss: 371154.5938 - val_loss: 373689.3125 - 72ms/epoch - 6ms/step\n",
            "Epoch 76/250\n",
            "12/12 - 0s - loss: 370252.1562 - val_loss: 373206.3125 - 89ms/epoch - 7ms/step\n",
            "Epoch 77/250\n",
            "12/12 - 0s - loss: 369837.0938 - val_loss: 372731.8125 - 73ms/epoch - 6ms/step\n",
            "Epoch 78/250\n",
            "12/12 - 0s - loss: 369288.6562 - val_loss: 372258.5938 - 75ms/epoch - 6ms/step\n",
            "Epoch 79/250\n",
            "12/12 - 0s - loss: 368839.5000 - val_loss: 371781.1875 - 81ms/epoch - 7ms/step\n",
            "Epoch 80/250\n",
            "12/12 - 0s - loss: 367982.6562 - val_loss: 371299.0625 - 85ms/epoch - 7ms/step\n",
            "Epoch 81/250\n",
            "12/12 - 0s - loss: 367965.5625 - val_loss: 370824.8750 - 82ms/epoch - 7ms/step\n",
            "Epoch 82/250\n",
            "12/12 - 0s - loss: 367544.1875 - val_loss: 370350.5000 - 92ms/epoch - 8ms/step\n",
            "Epoch 83/250\n",
            "12/12 - 0s - loss: 367099.3125 - val_loss: 369890.0625 - 77ms/epoch - 6ms/step\n",
            "Epoch 84/250\n",
            "12/12 - 0s - loss: 366533.9062 - val_loss: 369412.2500 - 75ms/epoch - 6ms/step\n",
            "Epoch 85/250\n",
            "12/12 - 0s - loss: 366399.1875 - val_loss: 368949.4375 - 76ms/epoch - 6ms/step\n",
            "Epoch 86/250\n",
            "12/12 - 0s - loss: 365505.2188 - val_loss: 368474.8438 - 95ms/epoch - 8ms/step\n",
            "Epoch 87/250\n",
            "12/12 - 0s - loss: 365209.5938 - val_loss: 367997.4375 - 89ms/epoch - 7ms/step\n",
            "Epoch 88/250\n",
            "12/12 - 0s - loss: 364325.9375 - val_loss: 367526.0938 - 92ms/epoch - 8ms/step\n",
            "Epoch 89/250\n",
            "12/12 - 0s - loss: 364099.0938 - val_loss: 367070.2812 - 91ms/epoch - 8ms/step\n",
            "Epoch 90/250\n",
            "12/12 - 0s - loss: 364088.3750 - val_loss: 366604.7812 - 73ms/epoch - 6ms/step\n",
            "Epoch 91/250\n",
            "12/12 - 0s - loss: 363075.6875 - val_loss: 366141.9375 - 74ms/epoch - 6ms/step\n",
            "Epoch 92/250\n",
            "12/12 - 0s - loss: 362832.2812 - val_loss: 365674.9375 - 84ms/epoch - 7ms/step\n",
            "Epoch 93/250\n",
            "12/12 - 0s - loss: 362256.9062 - val_loss: 365211.9062 - 76ms/epoch - 6ms/step\n",
            "Epoch 94/250\n",
            "12/12 - 0s - loss: 362071.1875 - val_loss: 364736.2500 - 73ms/epoch - 6ms/step\n",
            "Epoch 95/250\n",
            "12/12 - 0s - loss: 361556.6875 - val_loss: 364276.0000 - 90ms/epoch - 8ms/step\n",
            "Epoch 96/250\n",
            "12/12 - 0s - loss: 360740.0312 - val_loss: 363823.7500 - 90ms/epoch - 7ms/step\n",
            "Epoch 97/250\n",
            "12/12 - 0s - loss: 360353.5625 - val_loss: 363359.1875 - 81ms/epoch - 7ms/step\n",
            "Epoch 98/250\n",
            "12/12 - 0s - loss: 360609.8125 - val_loss: 362899.0625 - 93ms/epoch - 8ms/step\n",
            "Epoch 99/250\n",
            "12/12 - 0s - loss: 359403.8438 - val_loss: 362434.9062 - 74ms/epoch - 6ms/step\n",
            "Epoch 100/250\n",
            "12/12 - 0s - loss: 358906.3750 - val_loss: 361982.3125 - 77ms/epoch - 6ms/step\n",
            "Epoch 101/250\n",
            "12/12 - 0s - loss: 358839.6562 - val_loss: 361523.0938 - 82ms/epoch - 7ms/step\n",
            "Epoch 102/250\n",
            "12/12 - 0s - loss: 358551.0000 - val_loss: 361078.6875 - 91ms/epoch - 8ms/step\n",
            "Epoch 103/250\n",
            "12/12 - 0s - loss: 357753.9375 - val_loss: 360609.9688 - 78ms/epoch - 7ms/step\n",
            "Epoch 104/250\n",
            "12/12 - 0s - loss: 357556.3750 - val_loss: 360163.4375 - 87ms/epoch - 7ms/step\n",
            "Epoch 105/250\n",
            "12/12 - 0s - loss: 356795.2188 - val_loss: 359706.6875 - 74ms/epoch - 6ms/step\n",
            "Epoch 106/250\n",
            "12/12 - 0s - loss: 356464.0312 - val_loss: 359263.3438 - 92ms/epoch - 8ms/step\n",
            "Epoch 107/250\n",
            "12/12 - 0s - loss: 356363.7188 - val_loss: 358814.0625 - 90ms/epoch - 7ms/step\n",
            "Epoch 108/250\n",
            "12/12 - 0s - loss: 355239.5938 - val_loss: 358352.3125 - 88ms/epoch - 7ms/step\n",
            "Epoch 109/250\n",
            "12/12 - 0s - loss: 355200.9062 - val_loss: 357895.8438 - 94ms/epoch - 8ms/step\n",
            "Epoch 110/250\n",
            "12/12 - 0s - loss: 354329.0000 - val_loss: 357445.6875 - 91ms/epoch - 8ms/step\n",
            "Epoch 111/250\n",
            "12/12 - 0s - loss: 354414.9688 - val_loss: 356984.6562 - 90ms/epoch - 7ms/step\n",
            "Epoch 112/250\n",
            "12/12 - 0s - loss: 354083.2500 - val_loss: 356530.0000 - 73ms/epoch - 6ms/step\n",
            "Epoch 113/250\n",
            "12/12 - 0s - loss: 353454.5312 - val_loss: 356089.0625 - 75ms/epoch - 6ms/step\n",
            "Epoch 114/250\n",
            "12/12 - 0s - loss: 353004.8438 - val_loss: 355635.4062 - 91ms/epoch - 8ms/step\n",
            "Epoch 115/250\n",
            "12/12 - 0s - loss: 352704.5312 - val_loss: 355194.5312 - 99ms/epoch - 8ms/step\n",
            "Epoch 116/250\n",
            "12/12 - 0s - loss: 352111.5625 - val_loss: 354750.6562 - 70ms/epoch - 6ms/step\n",
            "Epoch 117/250\n",
            "12/12 - 0s - loss: 351762.2188 - val_loss: 354304.3438 - 74ms/epoch - 6ms/step\n",
            "Epoch 118/250\n",
            "12/12 - 0s - loss: 351476.1562 - val_loss: 353850.1562 - 73ms/epoch - 6ms/step\n",
            "Epoch 119/250\n",
            "12/12 - 0s - loss: 350878.8125 - val_loss: 353408.5625 - 78ms/epoch - 7ms/step\n",
            "Epoch 120/250\n",
            "12/12 - 0s - loss: 351070.2188 - val_loss: 352969.1875 - 90ms/epoch - 8ms/step\n",
            "Epoch 121/250\n",
            "12/12 - 0s - loss: 349717.3750 - val_loss: 352529.0625 - 80ms/epoch - 7ms/step\n",
            "Epoch 122/250\n",
            "12/12 - 0s - loss: 349296.6250 - val_loss: 352086.7188 - 95ms/epoch - 8ms/step\n",
            "Epoch 123/250\n",
            "12/12 - 0s - loss: 349744.5000 - val_loss: 351653.3125 - 92ms/epoch - 8ms/step\n",
            "Epoch 124/250\n",
            "12/12 - 0s - loss: 348647.0938 - val_loss: 351210.5938 - 91ms/epoch - 8ms/step\n",
            "Epoch 125/250\n",
            "12/12 - 0s - loss: 348051.5312 - val_loss: 350773.6875 - 97ms/epoch - 8ms/step\n",
            "Epoch 126/250\n",
            "12/12 - 0s - loss: 347570.6875 - val_loss: 350328.6250 - 100ms/epoch - 8ms/step\n",
            "Epoch 127/250\n",
            "12/12 - 0s - loss: 347360.1875 - val_loss: 349883.9688 - 91ms/epoch - 8ms/step\n",
            "Epoch 128/250\n",
            "12/12 - 0s - loss: 346918.5000 - val_loss: 349437.5000 - 93ms/epoch - 8ms/step\n",
            "Epoch 129/250\n",
            "12/12 - 0s - loss: 347140.0625 - val_loss: 349010.5625 - 78ms/epoch - 7ms/step\n",
            "Epoch 130/250\n",
            "12/12 - 0s - loss: 346004.5938 - val_loss: 348571.8438 - 91ms/epoch - 8ms/step\n",
            "Epoch 131/250\n",
            "12/12 - 0s - loss: 345694.5312 - val_loss: 348130.7500 - 77ms/epoch - 6ms/step\n",
            "Epoch 132/250\n",
            "12/12 - 0s - loss: 345566.9688 - val_loss: 347689.8438 - 74ms/epoch - 6ms/step\n",
            "Epoch 133/250\n",
            "12/12 - 0s - loss: 344263.5938 - val_loss: 347248.1250 - 93ms/epoch - 8ms/step\n",
            "Epoch 134/250\n",
            "12/12 - 0s - loss: 344808.9688 - val_loss: 346817.1562 - 91ms/epoch - 8ms/step\n",
            "Epoch 135/250\n",
            "12/12 - 0s - loss: 344051.3750 - val_loss: 346382.3125 - 78ms/epoch - 6ms/step\n",
            "Epoch 136/250\n",
            "12/12 - 0s - loss: 343735.6562 - val_loss: 345962.0312 - 76ms/epoch - 6ms/step\n",
            "Epoch 137/250\n",
            "12/12 - 0s - loss: 343613.4688 - val_loss: 345522.1875 - 80ms/epoch - 7ms/step\n",
            "Epoch 138/250\n",
            "12/12 - 0s - loss: 342804.0000 - val_loss: 345096.0938 - 89ms/epoch - 7ms/step\n",
            "Epoch 139/250\n",
            "12/12 - 0s - loss: 342943.4688 - val_loss: 344667.1875 - 90ms/epoch - 8ms/step\n",
            "Epoch 140/250\n",
            "12/12 - 0s - loss: 341711.5625 - val_loss: 344245.9062 - 71ms/epoch - 6ms/step\n",
            "Epoch 141/250\n",
            "12/12 - 0s - loss: 341555.2812 - val_loss: 343817.2188 - 91ms/epoch - 8ms/step\n",
            "Epoch 142/250\n",
            "12/12 - 0s - loss: 341127.4062 - val_loss: 343392.4062 - 72ms/epoch - 6ms/step\n",
            "Epoch 143/250\n",
            "12/12 - 0s - loss: 340838.3125 - val_loss: 342961.2188 - 78ms/epoch - 6ms/step\n",
            "Epoch 144/250\n",
            "12/12 - 0s - loss: 340558.6875 - val_loss: 342540.5312 - 72ms/epoch - 6ms/step\n",
            "Epoch 145/250\n",
            "12/12 - 0s - loss: 340064.5938 - val_loss: 342106.3125 - 81ms/epoch - 7ms/step\n",
            "Epoch 146/250\n",
            "12/12 - 0s - loss: 339765.4062 - val_loss: 341678.2500 - 72ms/epoch - 6ms/step\n",
            "Epoch 147/250\n",
            "12/12 - 0s - loss: 339155.3750 - val_loss: 341264.6562 - 88ms/epoch - 7ms/step\n",
            "Epoch 148/250\n",
            "12/12 - 0s - loss: 338882.4375 - val_loss: 340843.6875 - 95ms/epoch - 8ms/step\n",
            "Epoch 149/250\n",
            "12/12 - 0s - loss: 338223.0000 - val_loss: 340417.8438 - 91ms/epoch - 8ms/step\n",
            "Epoch 150/250\n",
            "12/12 - 0s - loss: 337881.5000 - val_loss: 339999.5938 - 83ms/epoch - 7ms/step\n",
            "Epoch 151/250\n",
            "12/12 - 0s - loss: 337327.3750 - val_loss: 339579.6250 - 88ms/epoch - 7ms/step\n",
            "Epoch 152/250\n",
            "12/12 - 0s - loss: 336683.2188 - val_loss: 339151.9375 - 75ms/epoch - 6ms/step\n",
            "Epoch 153/250\n",
            "12/12 - 0s - loss: 336236.0312 - val_loss: 338723.2500 - 78ms/epoch - 7ms/step\n",
            "Epoch 154/250\n",
            "12/12 - 0s - loss: 336016.5000 - val_loss: 338303.5625 - 90ms/epoch - 7ms/step\n",
            "Epoch 155/250\n",
            "12/12 - 0s - loss: 335905.8125 - val_loss: 337889.3438 - 93ms/epoch - 8ms/step\n",
            "Epoch 156/250\n",
            "12/12 - 0s - loss: 335812.0625 - val_loss: 337475.8438 - 77ms/epoch - 6ms/step\n",
            "Epoch 157/250\n",
            "12/12 - 0s - loss: 334746.6250 - val_loss: 337052.9688 - 91ms/epoch - 8ms/step\n",
            "Epoch 158/250\n",
            "12/12 - 0s - loss: 334546.3438 - val_loss: 336629.1562 - 90ms/epoch - 8ms/step\n",
            "Epoch 159/250\n",
            "12/12 - 0s - loss: 334155.2812 - val_loss: 336210.8125 - 92ms/epoch - 8ms/step\n",
            "Epoch 160/250\n",
            "12/12 - 0s - loss: 333122.2812 - val_loss: 335794.3125 - 79ms/epoch - 7ms/step\n",
            "Epoch 161/250\n",
            "12/12 - 0s - loss: 333470.6562 - val_loss: 335371.8438 - 92ms/epoch - 8ms/step\n",
            "Epoch 162/250\n",
            "12/12 - 0s - loss: 332834.7500 - val_loss: 334956.1875 - 90ms/epoch - 7ms/step\n",
            "Epoch 163/250\n",
            "12/12 - 0s - loss: 332789.9062 - val_loss: 334535.6250 - 87ms/epoch - 7ms/step\n",
            "Epoch 164/250\n",
            "12/12 - 0s - loss: 332042.5000 - val_loss: 334112.8438 - 79ms/epoch - 7ms/step\n",
            "Epoch 165/250\n",
            "12/12 - 0s - loss: 331256.1250 - val_loss: 333701.3438 - 81ms/epoch - 7ms/step\n",
            "Epoch 166/250\n",
            "12/12 - 0s - loss: 331730.2188 - val_loss: 333277.4062 - 75ms/epoch - 6ms/step\n",
            "Epoch 167/250\n",
            "12/12 - 0s - loss: 331107.6875 - val_loss: 332856.7812 - 89ms/epoch - 7ms/step\n",
            "Epoch 168/250\n",
            "12/12 - 0s - loss: 330209.8438 - val_loss: 332439.3125 - 77ms/epoch - 6ms/step\n",
            "Epoch 169/250\n",
            "12/12 - 0s - loss: 330213.6250 - val_loss: 332019.3750 - 76ms/epoch - 6ms/step\n",
            "Epoch 170/250\n",
            "12/12 - 0s - loss: 329905.2812 - val_loss: 331595.3125 - 93ms/epoch - 8ms/step\n",
            "Epoch 171/250\n",
            "12/12 - 0s - loss: 329455.8750 - val_loss: 331187.6562 - 95ms/epoch - 8ms/step\n",
            "Epoch 172/250\n",
            "12/12 - 0s - loss: 328525.0000 - val_loss: 330772.9375 - 75ms/epoch - 6ms/step\n",
            "Epoch 173/250\n",
            "12/12 - 0s - loss: 328331.3750 - val_loss: 330358.0000 - 74ms/epoch - 6ms/step\n",
            "Epoch 174/250\n",
            "12/12 - 0s - loss: 327974.7188 - val_loss: 329952.1562 - 98ms/epoch - 8ms/step\n",
            "Epoch 175/250\n",
            "12/12 - 0s - loss: 327238.1875 - val_loss: 329544.1875 - 76ms/epoch - 6ms/step\n",
            "Epoch 176/250\n",
            "12/12 - 0s - loss: 326763.0625 - val_loss: 329128.7500 - 90ms/epoch - 7ms/step\n",
            "Epoch 177/250\n",
            "12/12 - 0s - loss: 326669.4688 - val_loss: 328714.4375 - 94ms/epoch - 8ms/step\n",
            "Epoch 178/250\n",
            "12/12 - 0s - loss: 326984.7500 - val_loss: 328309.3750 - 88ms/epoch - 7ms/step\n",
            "Epoch 179/250\n",
            "12/12 - 0s - loss: 326782.2500 - val_loss: 327898.8438 - 95ms/epoch - 8ms/step\n",
            "Epoch 180/250\n",
            "12/12 - 0s - loss: 325943.9688 - val_loss: 327492.4375 - 73ms/epoch - 6ms/step\n",
            "Epoch 181/250\n",
            "12/12 - 0s - loss: 325550.4688 - val_loss: 327097.0000 - 91ms/epoch - 8ms/step\n",
            "Epoch 182/250\n",
            "12/12 - 0s - loss: 324825.6875 - val_loss: 326687.0938 - 82ms/epoch - 7ms/step\n",
            "Epoch 183/250\n",
            "12/12 - 0s - loss: 324389.5625 - val_loss: 326276.5625 - 74ms/epoch - 6ms/step\n",
            "Epoch 184/250\n",
            "12/12 - 0s - loss: 324009.9688 - val_loss: 325859.8125 - 126ms/epoch - 10ms/step\n",
            "Epoch 185/250\n",
            "12/12 - 0s - loss: 323969.8438 - val_loss: 325460.7188 - 126ms/epoch - 10ms/step\n",
            "Epoch 186/250\n",
            "12/12 - 0s - loss: 323237.0938 - val_loss: 325055.6562 - 123ms/epoch - 10ms/step\n",
            "Epoch 187/250\n",
            "12/12 - 0s - loss: 322113.6562 - val_loss: 324652.4375 - 103ms/epoch - 9ms/step\n",
            "Epoch 188/250\n",
            "12/12 - 0s - loss: 321451.8125 - val_loss: 324242.0000 - 132ms/epoch - 11ms/step\n",
            "Epoch 189/250\n",
            "12/12 - 0s - loss: 322474.8438 - val_loss: 323836.5938 - 116ms/epoch - 10ms/step\n",
            "Epoch 190/250\n",
            "12/12 - 0s - loss: 321513.6250 - val_loss: 323432.8438 - 114ms/epoch - 9ms/step\n",
            "Epoch 191/250\n",
            "12/12 - 0s - loss: 321733.4375 - val_loss: 323031.7188 - 113ms/epoch - 9ms/step\n",
            "Epoch 192/250\n",
            "12/12 - 0s - loss: 321362.9688 - val_loss: 322623.8750 - 100ms/epoch - 8ms/step\n",
            "Epoch 193/250\n",
            "12/12 - 0s - loss: 321166.0938 - val_loss: 322219.1875 - 108ms/epoch - 9ms/step\n",
            "Epoch 194/250\n",
            "12/12 - 0s - loss: 321444.4062 - val_loss: 321817.7188 - 121ms/epoch - 10ms/step\n",
            "Epoch 195/250\n",
            "12/12 - 0s - loss: 319513.9062 - val_loss: 321422.5312 - 125ms/epoch - 10ms/step\n",
            "Epoch 196/250\n",
            "12/12 - 0s - loss: 319191.1250 - val_loss: 321028.6562 - 123ms/epoch - 10ms/step\n",
            "Epoch 197/250\n",
            "12/12 - 0s - loss: 319206.2188 - val_loss: 320631.1562 - 114ms/epoch - 9ms/step\n",
            "Epoch 198/250\n",
            "12/12 - 0s - loss: 318474.6562 - val_loss: 320229.4375 - 129ms/epoch - 11ms/step\n",
            "Epoch 199/250\n",
            "12/12 - 0s - loss: 317948.3125 - val_loss: 319826.5938 - 131ms/epoch - 11ms/step\n",
            "Epoch 200/250\n",
            "12/12 - 0s - loss: 316842.8438 - val_loss: 319415.0000 - 135ms/epoch - 11ms/step\n",
            "Epoch 201/250\n",
            "12/12 - 0s - loss: 317722.2812 - val_loss: 319013.9375 - 110ms/epoch - 9ms/step\n",
            "Epoch 202/250\n",
            "12/12 - 0s - loss: 316808.3750 - val_loss: 318615.5938 - 92ms/epoch - 8ms/step\n",
            "Epoch 203/250\n",
            "12/12 - 0s - loss: 316344.0312 - val_loss: 318209.2500 - 82ms/epoch - 7ms/step\n",
            "Epoch 204/250\n",
            "12/12 - 0s - loss: 316191.6875 - val_loss: 317817.3438 - 83ms/epoch - 7ms/step\n",
            "Epoch 205/250\n",
            "12/12 - 0s - loss: 316298.5625 - val_loss: 317420.0625 - 95ms/epoch - 8ms/step\n",
            "Epoch 206/250\n",
            "12/12 - 0s - loss: 315452.8438 - val_loss: 317031.8438 - 99ms/epoch - 8ms/step\n",
            "Epoch 207/250\n",
            "12/12 - 0s - loss: 315223.8438 - val_loss: 316642.5625 - 75ms/epoch - 6ms/step\n",
            "Epoch 208/250\n",
            "12/12 - 0s - loss: 315165.1562 - val_loss: 316250.1562 - 75ms/epoch - 6ms/step\n",
            "Epoch 209/250\n",
            "12/12 - 0s - loss: 313951.0938 - val_loss: 315860.1562 - 81ms/epoch - 7ms/step\n",
            "Epoch 210/250\n",
            "12/12 - 0s - loss: 314085.5312 - val_loss: 315483.0312 - 73ms/epoch - 6ms/step\n",
            "Epoch 211/250\n",
            "12/12 - 0s - loss: 312944.7188 - val_loss: 315085.0625 - 72ms/epoch - 6ms/step\n",
            "Epoch 212/250\n",
            "12/12 - 0s - loss: 313216.1875 - val_loss: 314683.5312 - 89ms/epoch - 7ms/step\n",
            "Epoch 213/250\n",
            "12/12 - 0s - loss: 312814.4688 - val_loss: 314287.5625 - 88ms/epoch - 7ms/step\n",
            "Epoch 214/250\n",
            "12/12 - 0s - loss: 312843.0625 - val_loss: 313910.1875 - 100ms/epoch - 8ms/step\n",
            "Epoch 215/250\n",
            "12/12 - 0s - loss: 312117.5625 - val_loss: 313519.3125 - 89ms/epoch - 7ms/step\n",
            "Epoch 216/250\n",
            "12/12 - 0s - loss: 311961.4375 - val_loss: 313141.4688 - 79ms/epoch - 7ms/step\n",
            "Epoch 217/250\n",
            "12/12 - 0s - loss: 311489.7500 - val_loss: 312748.1875 - 89ms/epoch - 7ms/step\n",
            "Epoch 218/250\n",
            "12/12 - 0s - loss: 310828.0938 - val_loss: 312357.7500 - 76ms/epoch - 6ms/step\n",
            "Epoch 219/250\n",
            "12/12 - 0s - loss: 310609.7812 - val_loss: 311969.8125 - 77ms/epoch - 6ms/step\n",
            "Epoch 220/250\n",
            "12/12 - 0s - loss: 309482.5938 - val_loss: 311577.6875 - 83ms/epoch - 7ms/step\n",
            "Epoch 221/250\n",
            "12/12 - 0s - loss: 310114.9062 - val_loss: 311192.6250 - 95ms/epoch - 8ms/step\n",
            "Epoch 222/250\n",
            "12/12 - 0s - loss: 309551.8125 - val_loss: 310803.2812 - 87ms/epoch - 7ms/step\n",
            "Epoch 223/250\n",
            "12/12 - 0s - loss: 308836.2188 - val_loss: 310411.6875 - 78ms/epoch - 7ms/step\n",
            "Epoch 224/250\n",
            "12/12 - 0s - loss: 309396.2812 - val_loss: 310023.8125 - 73ms/epoch - 6ms/step\n",
            "Epoch 225/250\n",
            "12/12 - 0s - loss: 308832.2188 - val_loss: 309632.0625 - 89ms/epoch - 7ms/step\n",
            "Epoch 226/250\n",
            "12/12 - 0s - loss: 307584.7812 - val_loss: 309231.8750 - 89ms/epoch - 7ms/step\n",
            "Epoch 227/250\n",
            "12/12 - 0s - loss: 306819.0000 - val_loss: 308839.6250 - 81ms/epoch - 7ms/step\n",
            "Epoch 228/250\n",
            "12/12 - 0s - loss: 306958.8438 - val_loss: 308440.4375 - 89ms/epoch - 7ms/step\n",
            "Epoch 229/250\n",
            "12/12 - 0s - loss: 306389.3438 - val_loss: 308056.2188 - 92ms/epoch - 8ms/step\n",
            "Epoch 230/250\n",
            "12/12 - 0s - loss: 307041.7188 - val_loss: 307669.4062 - 76ms/epoch - 6ms/step\n",
            "Epoch 231/250\n",
            "12/12 - 0s - loss: 305531.5625 - val_loss: 307293.4688 - 75ms/epoch - 6ms/step\n",
            "Epoch 232/250\n",
            "12/12 - 0s - loss: 305891.1562 - val_loss: 306911.0625 - 77ms/epoch - 6ms/step\n",
            "Epoch 233/250\n",
            "12/12 - 0s - loss: 305180.2500 - val_loss: 306526.0938 - 78ms/epoch - 7ms/step\n",
            "Epoch 234/250\n",
            "12/12 - 0s - loss: 304261.4062 - val_loss: 306137.5625 - 90ms/epoch - 7ms/step\n",
            "Epoch 235/250\n",
            "12/12 - 0s - loss: 305127.1875 - val_loss: 305751.5000 - 92ms/epoch - 8ms/step\n",
            "Epoch 236/250\n",
            "12/12 - 0s - loss: 304092.8750 - val_loss: 305364.4375 - 74ms/epoch - 6ms/step\n",
            "Epoch 237/250\n",
            "12/12 - 0s - loss: 303221.2500 - val_loss: 304981.4375 - 87ms/epoch - 7ms/step\n",
            "Epoch 238/250\n",
            "12/12 - 0s - loss: 303738.0312 - val_loss: 304608.5625 - 77ms/epoch - 6ms/step\n",
            "Epoch 239/250\n",
            "12/12 - 0s - loss: 304205.5312 - val_loss: 304228.7188 - 72ms/epoch - 6ms/step\n",
            "Epoch 240/250\n",
            "12/12 - 0s - loss: 301753.4375 - val_loss: 303844.2812 - 73ms/epoch - 6ms/step\n",
            "Epoch 241/250\n",
            "12/12 - 0s - loss: 302765.6250 - val_loss: 303470.7188 - 78ms/epoch - 6ms/step\n",
            "Epoch 242/250\n",
            "12/12 - 0s - loss: 302327.0625 - val_loss: 303087.4688 - 89ms/epoch - 7ms/step\n",
            "Epoch 243/250\n",
            "12/12 - 0s - loss: 301309.6562 - val_loss: 302714.0625 - 80ms/epoch - 7ms/step\n",
            "Epoch 244/250\n",
            "12/12 - 0s - loss: 300914.5625 - val_loss: 302345.9375 - 83ms/epoch - 7ms/step\n",
            "Epoch 245/250\n",
            "12/12 - 0s - loss: 300404.7188 - val_loss: 301967.0312 - 89ms/epoch - 7ms/step\n",
            "Epoch 246/250\n",
            "12/12 - 0s - loss: 299967.0625 - val_loss: 301599.1562 - 95ms/epoch - 8ms/step\n",
            "Epoch 247/250\n",
            "12/12 - 0s - loss: 299853.1250 - val_loss: 301222.1562 - 73ms/epoch - 6ms/step\n",
            "Epoch 248/250\n",
            "12/12 - 0s - loss: 298922.6250 - val_loss: 300845.0625 - 74ms/epoch - 6ms/step\n",
            "Epoch 249/250\n",
            "12/12 - 0s - loss: 299095.8125 - val_loss: 300480.5000 - 97ms/epoch - 8ms/step\n",
            "Epoch 250/250\n",
            "12/12 - 0s - loss: 299514.8438 - val_loss: 300112.3125 - 92ms/epoch - 8ms/step\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 299219.9062\n",
            "Index: BANKEX, Test MSE: 299219.90625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_features(df):\n",
        "    features = df[['daysToExpiry', 'intradayMovement', 'intradayTotal', 'overnightExpected', 'overnightGap',\n",
        "                   'index_close', 'index_high', 'index_low', 'index_open']]\n",
        "    return features\n",
        "\n",
        "def predict_next_day_data(df, model):\n",
        "    # Prepare features for prediction\n",
        "    features = create_features(df)\n",
        "    features = prepare_data(features)\n",
        "\n",
        "    # Make predictions using the model\n",
        "    predictions = model.predict(features)\n",
        "\n",
        "    # Denormalize predictions if needed (using scaler.inverse_transform)\n",
        "    # Store or display the predicted prices as required\n",
        "\n",
        "    return predictions\n",
        "\n",
        "data = {\n",
        "    'date': ['2024-03-14T00:00:00.000Z'],\n",
        "    'daysToExpiry': [2],\n",
        "    'intradayMovement': [220.70],\n",
        "    'intradayTotal': [233.15],\n",
        "    'overnightExpected': [195.25],\n",
        "    'overnightGap': [198.55],\n",
        "    'index_close': [22.15],\n",
        "    'index_high': [10.90],\n",
        "    'index_low': [22341.65],\n",
        "    'index_open': [22450.70]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Preprocess the data\n",
        "features = create_features(df)\n",
        "\n",
        "# Prepare data for LSTM model\n",
        "X = prepare_data(features)\n",
        "\n",
        "# Make predictions\n",
        "predicted_prices = lstm_model.predict(X)\n",
        "\n",
        "# Print or use the predicted prices as needed\n",
        "print(predicted_prices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-us0pj5plTVf",
        "outputId": "bd66dce0-7e74-4355-eeea-aef6fff03951"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 809ms/step\n",
            "[[110.716095 105.5973   110.51655  107.86923 ]]\n"
          ]
        }
      ]
    }
  ]
}
